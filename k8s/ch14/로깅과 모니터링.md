
## 14.1 로깅 시스템 구축
### 14.1.1 클러스터 레벨 로깅의 장점
kubectl logs 명령어를 사용하면 컨테이너 로그를 바로 확인할 수 있습니다. 그러면 왜 따로 클러스터 레벨의 로깅 시스템이 필요한가?

#### 로그 히스토리 저장
Pod가 실행되면 kubectl logs 명령어를 이용해 로그를 확인할 수 있지만, Pod가 죽게되면 로그 기록도 사라집니다. 그래서 클러스터 레벨의 로깅 시스템을 따로 구축해서 로그 기록을 저장하면 언제든지 과거의 로그 기록들을 확인할 수 있습니다.

#### 시스템 컴포넌트 로그 통합
쿠버네티스에는 컨테이너만이 아닌 kubelet 등과 같은 쿠버네티스 시스템 컴포넌트가 존재합니다. 보통 systemd를 통하여 쿠버네티스 컴포넌트를 실행하는데 이러한 시스템 컴포넌트 로그들도 동일한 로깅 시스템을 이용해서 기록을 확인할 수 있습니다.

#### 범용 로깅 플랫폼
개발자마다 따로 로깅 기능을 구현하지 않아도 되고 동일한 화면을 통해서 로그를 볼수 있습니다.

위와 같은 이유로 쿠버네티스에서 클러스터 레벨의 로깅 시스템을 따로 구축해서 사용합니다. 이번장에서는 EFK 스택(ElasticSearch, fluent-bit, Kibana)을 이용해서 로깅 시스템을 구축하는 방법에 대해서 살펴봅니다.

### 4.1.2 클러스터 레벨 로깅 원리
도커에서 컨테이너의 로그를 확인하기 위해서 다음과 같은 형식으로 확인합니다.
```shell
docker logs {CONTAINER_ID}
```

도커 컨테이너 로그는 호스트 서버의 특정 디렉토리에 저장이 됩니다. 사용자는 직접 호스트 운영체제의 디렉토리에 접근하여 로그를 확인할 수도 있습니다. 호스트 서버의 디렉토리 위치 형식은 다음과 같습니다.
```shell
/var/lib/docker/containers/{CONTAINER_ID}/{CONTAINER_ID}-json.log
```

예를 들어 직접 호스트 서버의 로그 기록을 확인해봅니다. 로그 기록을 확인하기 위해서 nginx 컨테이너를 실행합니다.
```shell
docker run -d nginx
```
![[Pasted image 20250321113743.png]]

docker logs 명령어를 이용해서 생성한 컨테이너의 로그를 확인합니다.
```shell
docker logs 268a06222f909ac9edf5b6f41cb4307cbd18e03980be5380ee8a58fb6cb9d5df
```
![[image-591.png]]
- 실행 결과를 보면 nginx 컨테이너의 로그를 확인할 수 있습니다.

이번에는 호스트 서버에 저장된 로그를 직접 확인해보겠습니다.
```shell
sudo tail /var/lib/docker/containers/268a06222f909ac9edf5b6f41cb4307cbd18e03980be5380ee8a58fb6cb9d5df/268a06222f909ac9edf5b6f41cb4307cbd18e03980be5380ee8a58fb6cb9d5df-json.log
```
![[image-592.png]]
- 실행 결과를 보면 호스트 서버에서 직접 조회한 로그에서도 동일한 로그가 출력된 것을 볼수 있습니다.

컨테이너를 삭제합니다.
```shell
docker stop 268a06222f909ac9edf5b6f41cb4307cbd18e03980be5380ee8a58fb6cb9d5df
docker rm 268a06222f909ac9edf5b6f41cb4307cbd18e03980be5380ee8a58fb6cb9d5df
```

위 예제를 통해서 알수 있는 사실은 모든 컨테이너의 로깅 정보가 호스트 서버에 저장되는 것을 알 수 있습니다.
로깅 정보가 호스트 서버에 저장되는 특징을 이용해서 로깅 수집기가 해당 디렉토리에 있는 정보를 수집해서 중앙 로그 저장소로 보내기만 하면 되므로, 쉽게 클러스터 레벨의 로깅 시스템을 구축할 수 있습니다.

### 14.1.3 ElasticSearch
ElasticSearch는 텍스트 검색에 최적화된 오픈소스 검색 엔진입니다. 

ElasticSearch에서 사용하는 다음과 같은 개념을 사용합니다.
- index
	- document의 집합으로 index를 기준으로 데이터를 질의하고 저장합니다. 데이터베이스의 table과 유사합니다.
- shard
	- 성능 향상을 위해 index를 나눈 것입니다.
	- 데이터베이스의 partition과 유사합니다.
- document
	- 1개의 행을 나타냅니다.
- field
	- document 안에 들어있는 열을 의미합니다.

엘라스틱 서치의 장단점은 다음과 같습니다.
- 장점
	- 비정형 데이터를 다룰 수 있는 유연함
	- 뛰어난 확장성과 가용성
	- Full Text 검색이 빠름
	- 계층적인 데이터도 쿼리 가능
	- RESTful API 지원
	- 준 실시간 쿼리
- 단점
	- 업데이트 비용이 큼
	- 트랜잭션 기능 부재
	- JSON 기능 부재

### 14.1.4 fluent-bit
- fluent-bit는 데이터 수집, 처리, 라우팅에 뛰어난 fluentd의 경량 버전 수집기입니다.
- fluentd는 로그를 수집하고 집계(aggregation)합니다.
- fluent-bit는 fluentd의 경량 버전입니다.
- fluent-bit는 로그를 수집 및 처리하고 다른 곳으로 데이터를 전달하는 반면에 데이터를 집계하는 기능은 없습니다.
- fluent-bit는 분산 환경에서 적은 리소스를 가지고 빠르게 데이터를 타겟 시스템에 전달하는 것을 목표로 설계되었기 때문입니다.
- fluent-bit는 애초에 컨테이너 환경을 염두에 두고 그곳에 맞게 최적의 성능을 내도록 만들어졌습니다.
- 모든 Pod들의 로그 파일이 /var/log/containers/*.log에 생성되어 해당 로그 위치의 파일들만 수집하여 elasticSearch로 전달하면 모든 컨테이너에 대해서 로깅을 수행할 수 있기 때문입니다.

### 14.1.5 Kibana
- Kibana는 웹을 통해 대시보드를 제공하는 데이터 시각화 플랫폼입니다.
- ElasticSearch에 보관되어 있는 데이터를 조회해서 다양한 시각 컴포넌트로 표현합니다.
- Kibana는 KQL이라는 질의 언어를 이용해서 Kibana 플랫폼에서 ElasticSearchfh 쿼리할 수 있습니다.

### 14.1.6 EFK Stack
- EFK Stack은 수집(fluent-bit), 저장(elastic-search), 시각화(kibana) 툴을 조합한 것입니다.
- helm chart를 이용하여 손쉽게 EFK stack을 구성할 수 있습니다.

#### Elastic Search + Kibana 설치
설치용 namsepace를 생성합니다.
```shell
kubectl create ns logging
```

bitnami 저장소를 등록합니다.
```shell
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update 
```

elasticsearch chart를 가져옵니다.
```shell
helm fetch --untar bitnami/elasticsearch --version 21.4.8
```

```shell
vim ./elasticsearch/values.yaml
```

values.yaml
- master.replicaCount=2
- coordinating.replicaCount=1
- data.replicaCount=1
- 

elasticsearch helm cart를 설치합니다.
```shell
helm install elasticsearch ./elasticsearch -n logging
```

