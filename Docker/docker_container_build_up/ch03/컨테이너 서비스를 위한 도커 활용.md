
- [[#3.1 컨테이너 서비스란|3.1 컨테이너 서비스란]]
	- [[#3.1 컨테이너 서비스란#3.1.1 컨테이너 서비스란?|3.1.1 컨테이너 서비스란?]]
	- [[#3.1 컨테이너 서비스란#3.1.2 왜 도커 컨테이너 서비스를 사용하는가|3.1.2 왜 도커 컨테이너 서비스를 사용하는가]]
- [[#3.2 도커 명령어 활용|3.2 도커 명령어 활용]]
	- [[#3.2 도커 명령어 활용#3.2.1 도커 이미지 명령어|3.2.1 도커 이미지 명령어]]
		- [[#3.2.1 도커 이미지 명령어#도커 이미지 태그 설정과 도커 로그인 및 로그아웃|도커 이미지 태그 설정과 도커 로그인 및 로그아웃]]
		- [[#3.2.1 도커 이미지 명령어#도커 로그인 방법 1 : username, password를 이용한 방법|도커 로그인 방법 1 : username, password를 이용한 방법]]
		- [[#3.2.1 도커 이미지 명령어#도커 로그인 방법 2 : AccessToken을 이용한 방법|도커 로그인 방법 2 : AccessToken을 이용한 방법]]
		- [[#3.2.1 도커 이미지 명령어#도커 이미지를 파일로 관리|도커 이미지를 파일로 관리]]
		- [[#3.2.1 도커 이미지 명령어#도커 이미지 삭제|도커 이미지 삭제]]
	- [[#3.2 도커 명령어 활용#3.2.2 도커 컨테이너 명령어|3.2.2 도커 컨테이너 명령어]]
		- [[#3.2.2 도커 컨테이너 명령어#컨테이너는 프로세스이다|컨테이너는 프로세스이다]]
		- [[#3.2.2 도커 컨테이너 명령어#컨테이너 실행|컨테이너 실행]]
		- [[#3.2.2 도커 컨테이너 명령어#SQL 테스트를 위한 개발팀의 요청으로 MySQL 5.7 실행|SQL 테스트를 위한 개발팀의 요청으로 MySQL 5.7 실행]]
		- [[#3.2.2 도커 컨테이너 명령어#컨테이너 모니터링 도구 cAdvisor 컨테이너 실행|컨테이너 모니터링 도구 cAdvisor 컨테이너 실행]]
		- [[#3.2.2 도커 컨테이너 명령어#웹 서비스 실행을 위한 Nginx 컨테이너 실행|웹 서비스 실행을 위한 Nginx 컨테이너 실행]]
		- [[#3.2.2 도커 컨테이너 명령어#파이썬 프로그래밍 환경을 컨테이너로 제공|파이썬 프로그래밍 환경을 컨테이너로 제공]]
	- [[#3.2 도커 명령어 활용#3.2.3 도커 볼륨 활용|3.2.3 도커 볼륨 활용]]
		- [[#3.2.3 도커 볼륨 활용#도커 볼륨 타입|도커 볼륨 타입]]
		- [[#3.2.3 도커 볼륨 활용#도커 볼륨 활용|도커 볼륨 활용]]
	- [[#3.2 도커 명령어 활용#3.2.4 도커 컨테이너의 자원 사용에 대한 런타임 제약|3.2.4 도커 컨테이너의 자원 사용에 대한 런타임 제약]]
		- [[#3.2.4 도커 컨테이너의 자원 사용에 대한 런타임 제약#컨테이너 리소스 런타임 제약 옵션|컨테이너 리소스 런타임 제약 옵션]]
	- [[#3.2 도커 명령어 활용#3.2.5 도커 네트워크|3.2.5 도커 네트워크]]
		- [[#3.2.5 도커 네트워크#도커 네트워크 개요|도커 네트워크 개요]]
		- [[#3.2.5 도커 네트워크#도커 기본 브리지 네트워크 활용|도커 기본 브리지 네트워크 활용]]
		- [[#3.2.5 도커 네트워크#도커 사용자 정의 네트워크 활용|도커 사용자 정의 네트워크 활용]]
	- [[#3.2 도커 명령어 활용#3.2.6 도커 kill 명령과 초기화|3.2.6 도커 kill 명령과 초기화]]

# 3.1 컨테이너 서비스란
## 3.1.1 컨테이너 서비스란?
컨테이너에 내가 개발한 애플레케이션의 코드와 실행중인 프로그램을 격리하여 실행하는 서비스

#### 애플리케이션 개발환경이 도커 기반의 컨테이너 서비스 환경으로 전환된 이유는 무엇인가
가변적인 인프라 환경으로 인한 일관성이 없는 환경의 제공때문이다.
위 의미는 개발, 테스트, 배포, 운영의 컴퓨팅 환경(저장소, 네트워크, 보안, 패치 등) 차이로 인한 시행착오와 오류 해결에 너무 많은 시간을 쏟는 문제가 있다는 의미이다.

#### 컨테이너 서비스가 해결한 문제
애플리케이션이 가지고 있는 운영체제, 하드웨어(CPU, 메모리, 스토리지 등)에 대한 의존성 문제를 해결하였다.
- 하드웨어 레벨 가상화
	- 하이퍼바이저 등을 이용한 가상머신의 방식을 말한다. EX) VMWARE, VIRTUAL BOX
- 운영체제 레벨 가상화
	- 컨테이너 기반의 애플리케이션 서비스 방식을 말한다.
	- 운영체제 레벨 가상화는 호스트 운영체제를 공유하고 애플리케이션에 필요한 환경을 패키징한다.

## 3.1.2 왜 도커 컨테이너 서비스를 사용하는가
도커 컨테이너 서비스를 사용하여 개발자는 애플리케이션 개발, 테스트, 배포 시마다 모든 인프라 구성 요소를 하나하나 수동적으로 체크하거나

맞출 필요가 없고, **변경 불가능한 인프라** 환경에서 언제든 동일한 상태에서의 개발이 가능해진다.

![[img/image-754.png]]

1. 애플리케이션 코드 개발
애플레케이션 코드 및 웹 화면을 위한 코드를 개발한다

2. 베이스 이미지를 이용한 Dockerfile 작성
개발에 필요한 구성 요소를 Dockerfile에 작성한다.

도커 허브에서 베이스 이미지를 다운로드하고 구동 명령어(FROM, RUN, CMD, ENDPOINT, ENV, ADD 등)와 1에서 작성한 애플리케이션 코드,

라이브러리, 여러 도구를 Dockerfile에 포함시킨다

1. Dockerfile build를 통한 새로운 이미지 생성
docker build 명령을 통해 작성한 Dockerfile을 실행한다.

각 단계별로 실행되는 로그를 화면에서 확인하고 오류 발생 내용도 확인할 수 있다.


2. 컨테이너 실행
   1. 생성한 이미지를 이용한 컨테이너 실행
      - docker image 명령어를 통해 생성된 이미지를 확인하고 이미지를 통한 컨테이너를 구동한다.
   2. 도커 컴포즈를 이용한 다중 컨테이너 실행
      - docker-compose.yml을 통해 다중 컨테이너 간 실행 순서, 네트워크, 의존성 등을 통합 관리할 수 있고 아미크로서비스 개발에 활용한다.

3. 테스트
   1. 컨테이너 애플리케이션 서비스 테스트
      - 예를 들어, Nginx를 이용한 웹 애플리케이션 컨테이너 서비스였다면 연결하는 IP와 포트 번호를 이용하여 웹 브라우저를 이용한 페이지
      연결을 확인할 수 있다.
   2. 마이크로서비스 테스트
      - 5-1과 마찬가지로 해당 서비스에 대한 테스트를 진행한다.

4. 로컬 및 원격 저장소에 이미지 저장
로컬 및 원격에 있는 이미지 저장소에 생성한 이미지를 저장하여 다른 팀 간의 공유 및 지속적인 이미지 관리를 수행한다.

5. 깃허브 등을 활용한 Dockerfile 관리
Dockerfile 코드를 깃허브 사이트에 저장 및 관리할 수 있음

도커 허브 사이트와 연동하게 되면 자동화된 빌드 기능을 이용한 이미지 생성도 가능함

6. 동일 환경에서의 지속적 애플리케이션 개발 수행
1 ~ 7 과정을 통해 업무용 애플리케이션 이미지를 지속적으로 개발, 운영 및 관리할 수 있다.

# 3.2 도커 명령어 활용
## 3.2.1 도커 이미지 명령어

**도커 명령어 사용법 조회(help)**

docker 명령어에 대한 메뉴얼이 궁금하다면 다음과 같이 입력하여 조회할 수 있습니다.

```bash
docker {command} --help
```

예를 들어 도커 이미지를 검색하는 docker search 명령어 대한 메뉴얼 출력은 다음과 같이 입력합니다.

```bash
docker search --help
```

![image-212.png](img/image-212.png)

**도커 이미지 검색(docker search)**

예를 들어 ubuntu 도커 이미지를 검색하기 위해서 다음과 같이 실행합니다.

```bash
docker search ubuntu
```

![image.png](img/image-213.png)

- 위 실행 결과를 보면 도커 이미지 이름, 설명, 별점, **Docker 공식 이미지 여부**, 자동 빌드 여부(값이 “OK”이면 자동 빌드된 이미지)
- AUTOMATED 열은 자동 빌드 여부로써 해당 이미지는 Docker Hub의 자동 빌드 기능을 사용하여 빌드된 이미지를 나타냅니다. 이는 Docker Hub와 GitHub 또는 BitBucket 등의 소스 코드 저장소가 연동되어, 저장소의 Dockerfile을 기반으로 이미지를 자동으로 생성하고 업데이트했음을 의미합니다.
    - 예를 들어 우분투 운영체제의 소스 코드가 변경되어 깃허브 저장소로 푸시되면 깃허브는 Docker Hub에게 변경을 통지합니다. Docker Hub는 빌드 컨텍스트를 기반으로 새로운 이미지 빌드를 실행합니다.

**도커 이미지 내려받기(docker pull)**

docker pull 명령어를 사용하면 Docker Hub Registry에 저장된 이미지를 다운로드 받을 수 있습니다. 명령어 형식은 다음과 같습니다.

```bash
docker [image] pull [OPTIONS] name[:TAG | @IMAGE_DIGEST]
```

- docker image pull 또는 docker pull 명령어로 이미지 내려받기가 가능합니다.

예를 들어 debian 리눅스 이미지를 다운로드 받아보겠습니다.

```bash
docker pull debian
```

![image.png](img/image-214.png)

- 도커 이미지 내려받을시 별도 태그가 없으면 최신 버전(latest)을 내려받습니다.
- 다이제스트(digest) 값은 도커 허브에서 관리하는 이미지의 고유 식별값을 의미합니다.
- [docker.io](http://docker.io) : 도커 허브의 이미지 저장 주소를 의미합니다.

**도커 이미지 세부 정보 조회(docker image inspect, docker image history)**

도커 이미지나 컨테이너 등에 대한 세부 정보를 조회하기 위해서 docker image inspect 명령어나 docker image history 명령어를 사용할 수 있습니다.

**docker image inspect 명령어 형식**

```bash
docker image inspect [OPTIONS] IMAGE [IMAGE...]
```

예를 들어 httpd 도커 이미지를 다운로드 받아보고 세부 정보를 조회해봅니다.

```bash
docker search httpd
```

![image.png](img/image-215.png)

- httpd 이미지가 공식 이미지입니다.

httpd 이미지를 최신 버전으로 다운로드해봅니다.

```bash
docker pull httpd:latest
```

![image.png](img/image-216.png)

다운로드받은 httpd 이미지를 조회해봅니다.

```bash
docker images httpd
```

![image.png](img/image-217.png)

다운로드 받은 httpd 이미지의 세부 정보를 조회해봅니다.

```bash
docker image inspect httpd
```

![image.png](img/image-218.png)

- 실행시 많은 출력 내용 정보가 조회됩니다. 위 결과는 일부 결과 내용입니다.

docker image inspect 명령어 사용시 —format 옵션을 사용하여 특정 계층을 대상으로 조회할 수 있습니다. 예를 들어 위 실행 결과중 RepoTags 계층을 기준으로만 조회합니다. 분석 결과가 계층 형식으로 되어 있기 때문에 하위 정보 조회시 .상위[.하위] 방식으로 조회 가능합니다.

```bash
docker image inspect --format="{{.RepoTags}}" httpd
```

![image.png](img/image-219.png)

- 위 실행 결과를 보면 RepoTags 계층에는 배열로 구성되어 있고 “httpd:latest” 원소가 존재합니다.

이번에는 Os 계층을 조회해봅니다.

```bash
docker image inspect --format="{{.Os}}" httpd
```

![image.png](img/image-220.png)

- 실행 결과를 보면 해당 이미지의 운영체제는 linux입니다.

이미지가 생성된 일자 및 시간을 조회해봅니다.

```bash
docker image inspect --format="{{.Created}}" httpd
```

![image.png](img/image-221.png)

- 실행 결과를 보면 httpd 이미지가 생성된 시간은 2024-07-17일 23시 31분 14분입니다.

이번에는 컨테이너의 환경 변수 설정을 조회해봅니다.

```bash
docker image inspect --format="{{.Config.Env}}" httpd
```

![image.png](img/image-222.png)

- 실행 결과를 보면 PATH, HTTPD_PREFIX, HTTPD_VERSION, HTTP_SHA256 환경변수가 설정되어 있습니다.

마지막으로 RootFS.Layers 계층을 기준으로 조회해봅니다.

```bash
docker image inspect --format="{{.RootFS.Layers}}" httpd
```

![image.png](img/image-223.png)

- 실행 결과를 보면 여러개의 레이어가 쌓여 있습니다.

**도커 이미지 히스토리 조회(docker image history)**

docker image history 명령을 사용하여 이미지 구성에 사용된 레이블(label) 정보와 각 레이어의 수행 명령, 크기 등을 조회할 수 있습니다.

```java
docker image history [OPTIONS] IMAGE
```

- OPTIONS
    - —format string : 출력 정보를 특정한 형식으로 출력합니다.
        - table
        - json
    - —human, -H : 사람이 읽기 쉽게 사이즈와 데이터를 특정한 형식으로 출력합니다.
    - —quiet, -q : 이미지 ID만 출력

예를 들어 httpd 이미지의 이미지 정보를 조회합니다.

```java
docker image history httpd
```

```java
IMAGE          CREATED        CREATED BY                                       SIZE      COMMENT
062dcbdad052   6 months ago   CMD ["httpd-foreground"]                         0B        buildkit.dockerfile.v0
<missing>      6 months ago   EXPOSE map[80/tcp:{}]                            0B        buildkit.dockerfile.v0
<missing>      6 months ago   COPY httpd-foreground /usr/local/bin/ # buil…   138B      buildkit.dockerfile.v0
<missing>      6 months ago   STOPSIGNAL SIGWINCH                              0B        buildkit.dockerfile.v0
<missing>      6 months ago   RUN /bin/sh -c set -eux;   savedAptMark="$(a…   69.2MB    buildkit.dockerfile.v0
<missing>      6 months ago   ENV HTTPD_PATCHES=                               0B        buildkit.dockerfile.v0
<missing>      6 months ago   ENV HTTPD_SHA256=674188e7bf44ced82da8db522da…   0B        buildkit.dockerfile.v0
<missing>      6 months ago   ENV HTTPD_VERSION=2.4.62                         0B        buildkit.dockerfile.v0
<missing>      6 months ago   RUN /bin/sh -c set -eux;  apt-get update;  a…   11.4MB    buildkit.dockerfile.v0
<missing>      6 months ago   WORKDIR /usr/local/apache2                       0B        buildkit.dockerfile.v0
<missing>      6 months ago   RUN /bin/sh -c mkdir -p "$HTTPD_PREFIX"  && …   0B        buildkit.dockerfile.v0
<missing>      6 months ago   ENV PATH=/usr/local/apache2/bin:/usr/local/s…   0B        buildkit.dockerfile.v0
<missing>      6 months ago   ENV HTTPD_PREFIX=/usr/local/apache2              0B        buildkit.dockerfile.v0
<missing>      6 months ago   # debian.sh --arch 'arm64' out/ 'bookworm' '…   97.1MB    debuerreotype 0.15
```

- IMAGE : 이미지 ID
- CREATED : 생성일자
- CREATED BY : 이미지를 구성하기 위해 사용된 명령과 환경 설정 정보
- SIZE : 해당 레이어를 구성하기 위한 크기
- COMMENT : 이미지 레이어를 설명하기 위한 주석

위 실행 결과를 보면 CMD, EXPOSE ENV, WORKDIR 등의 명령어를 통해서 베이스 이미지에 필요한 설정 정보를 결합하여 새로운 이미지를 만듭니다.

이전의 명령어인 docker image inspect 명령어를 이용해서 이미지의 레이어를 확인합니다.

```java
docker image inspect httpd
```

![image.png](img/image-224.png)

실행 결과중에서 RootFS.Layers를 보면 이미지에 사용된 레이어들이 존재합니다. 여기서 출력된 다이제스트값은 도커 허브에서 관리하는 다이제스트값이 아닌 로컬에 다운로드될 때 생기는 레이어들의 Distribution ID입니다.

<aside>
💡

다이제스트(Digest)

특정 데이터를 고유하게 식별하기 위해 사용하는 고정된 길이의 해시값. Docker에서 다이제스트는 이미지, 레이어, 또는 특정 데이터의 무결성을 보장하고 고유성을 확인하기 위해 사용됩니다. 일반적으로 SHA256 해시 알고리즘 기반으로 생성됩니다.

</aside>

다음 경로로 이동하여 다이제스트 값을 확인할 수 있습니다.

```java
cd /var/lib/docker/image/overlay2/distribution/diffid-by-digest/sha256
```

![image.png](img/image-225.png)

도커 유니언 파일 시스템을 그림으로 표현하면 다음과 같습니다. 각각의 이미지들에는 이미지를 구성하기 위한 여러개의 레이어들로 구성되어 있습니다.

![image.png](img/image-226.png)

**도커 유니언 파일 시스템을 사용하는 이유는 무엇인가?**

- 컨테이너 실행할때마다 이미지를 각각 내려받지 않고 로컬에 저장된 이미지를 계속 사용하기 위해서입니다.
- 이미지 레이어 상단에 있는 웹 애플리케이션 소스 레이어의 환경 설정이나 리소스 설정이 변경되어 이미지가 변경되어도 기존 레이어를 제외한 변경한 웹 소스 레이어만 내려받아서 사용하기 때문에 효율적입니다.

이번에는 호스트 운영체제에서는 이미지 레이어가 어떻게 저장되는지 살펴봅니다.

우선은 도커 저장소에서 사용되는 스토리지 드라이버를 조회해봅니다. 실행 결과를 보면 Overlay2를 사용하고 있습니다.

```java
docker info | grep Storage
```

![image.png](img/image-227.png)

도커의 모든 데이터 및 로그 정보는 “/var/lib/docker” 경로에 저장됩니다. 해당 경로로 이동하기 위해서는 root 유저로 변경해야 합니다.

```java
sudo su -
root# cd /var/lib/docker
root# ls
```

![image.png](img/image-228.png)

이번에는 이미지 레이더 데이터가 저장되는 경로로 이동하여 데이터를 확인해보겠습니다.

```java
cd /var/lib/docker/image/overlay2/layerdb/sha256/
ls
```

![image.png](img/image-229.png)

- 출력된 디렉토리 이름은 다이제스트 값

내려받은 httpd 이미지의 저장된 레이어를 조회하고 첫번째 주소와 비교해서 일치하는 디렉토리가 있는지 확인해보겠습니다.

```java
docker image inspect --format="{{.RootFS.Layers}}" httpd
```

![image.png](img/image-230.png)

레이어의 다이제스트 값을 가진 디렉토리로 이동하고 cache-id 파일 정보를 통해서 실제 데이터가 저장된 디렉토리의 다이제스트 값을 확인합니다.

```java
cd f5fe472da25334617e6e6467c7ebce41e0ae5580e5bd0ecbf0d573bacd560ecb
ls
cat cache-id
```

![image.png](img/image-231.png)

실행 결과 실제 데이터가 저장된 디렉토리의 다이제스트값은 317…로 시작하는 디렉토리인 것을  알수 있습니다.

다음 경로로 다시 이동하여 cache-id를 통해서 출력된 다이제스트 값과 일치하는 디렉토리가 있는지 확인합니다.

```java
cd /var/lib/docker/overlay2
cd 317f9407fddccdfd06f6c1c1620282d4dbf64645565b30eda7a5901e73d677c9
```

![image.png](img/image-232.png)

이제 diff 디렉토리로 이동하여 실제 데이터를 확인해봅니다.

```java
cd diff
```

![image.png](img/image-233.png)

실행 결과를 보면 위 데이터가 httpd 이미지 실행을 통해 만들어지는 컨테이너의 최상위 경로 및 영역이 됩니다.

다른 터미널을 실행한 다음에 httpd 컨테이너를 실행해보겠습니다.

```java
docker run -it -p 888:888 --name=webserver httpd:latest /bin/bash
root@009b1b576b3c: cd /
root@009b1b576b3c: ls
```

![image.png](img/image-234.png)

다시 관리자 권한이 있는 루트 계정의 터미널에서 임시 파일을 생성해봅니다.

```java
root: touch Hello-docker
root: ls
```

![image.png](img/image-235.png)

실행 결과 성공적으로 Hello-docker 파일이 생성되었습니다.

다시 컨테이너로 접속한 터미널에서 위 단계에서 생성한 임시 파일 Hello-docker 파일이 있는지 확인합니다.

```java
root@009b1b576b3c: ls
```

![image.png](img/image-236.png)

실행 결과를 보면 컨테이너로 접속한 터미널에서 파일 확인시 Hello-docker 파일이 존재합니다.

우리는 위 예제를 통해서 로컬에서 httpd 레이어를 추적해서 그 위치를 파악하고 컨테이너가 그 레이어에서 수행되는 것을 확인할 수 있습니다.


### 도커 이미지 태그 설정과 도커 로그인 및 로그아웃

도커 태그는 원본 이미지에 참조 이미지 이름을 붙이는 명령어입니다. 도커 태그 명령어의 형식은 다음과 같습니다.

```java
docker tag 원본 이미지[:태그] 참조 이미지[:태그]
```

- 태그 설정은 단순히 새로운 참조명을 붙이는 작업이기 때문에 이미지 ID는 변경되지 않습니다.

docker images 명령어를 통해서 httpd 이미지의 ID를 확인합니다.

```java
docker images
```

![image.png](img/image-237.png)

- 실행 결과 f7d8bafbd9a9 인것을 확인합니다.

tag 명령어를 이용하여 httpd 이미지에 태그를 붙혀서 debian-httpd:1.0이라고 붙힙니다.

```java
docker image tag f7d8bafbd9a9 debian-httpd:1.0
```

![image.png](img/image-238.png)

이번에는 httpd 이미지 ID가 아닌 이미지 이름과 태그를 이용하여 다시 별도의 태그로 지정해보겠습니다.

```java
docker image tag httpd:latest debian-httpd:2.0
```

![image.png](img/image-239.png)

도커 허브와 같은 레지스트리에 업로드 하는 경우 저장소명과 함께 태그를 지정해야 합니다.

```java
docker image tag httpd:latest nemo1107/httpd:3.0
```

![image.png](img/image-240.png)

알기 쉬운 이름으로 설정하고자 하는 경우 태그를 다음과 같이 지정할 수 있습니다. 예를 들어 단순한 httpd:latest 가 아닌 webserver라는 이름으로 태그를 표현할 수 있습니다.

```java
docker image tag httpd webserver:4.0
```

![image.png](img/image-241.png)

도커 허브에 가입 후 본인 아이디 허브 저장소에 httpd:3.0을 다음과 같이 푸시하여 업로드합니다.

```java
docker push nemo1107/httpd:3.0
```

![image.png](img/image-242.png)

![image.png](img/image-243.png)

실행 결과를 보면 도커 허브 저장소에 nemo1107/httpd:3.0 이미지가 업로드되었습니다.

로컬 머신에서 nemo1107/httpd:3.0 이미지를 제거한 다음에 다시 내려받아보겠습니다.

```java
docker image rm nemo1107/httpd:3.0
docker pull nemo1107/httpd:3.0
```

![image.png](img/image-244.png)

### 도커 로그인 방법 1 : username, password를 이용한 방법

docker login 명령어를 이용하여 로컬 머신에서 로그인을 수행합니다.

```java
$ docker login
Username: 본인 아이디 입력
Password: 본인 암호 입력
```

도커를 로그인하고 나서 다음 파일의 내용을 보면 인증정보가 암호화되지 않고 아래 경로에 암호가 저장되어 있습니다. 다음 auth 값은 암호화 알고리즘이 아닌 base64 인코딩을 통한 암호 키값이 저장되어 있습니다. base64 디코딩이 가능하므로 주의해야 합니다.

```java
cat ~/.docker/config.json
```

![image.png](img/image-245.png)

현재 도커에 접속해 있는 사용자를 조회해봅니다. docker info 명령어 출력의 결과중 Username을 캐치하여 출력합니다.

```java
docker info | grep Username
```

![image.png](img/image-246.png)

실행 결과를 보면 현재 접속해 있는 사용자가 nemo1107 사용자인 것을 알수 있습니다.

docker logout 명령어를 이용하여 로그아웃해봅니다.

```java
docker logout
```

![image.png](img/image-247.png)

도커를 로그아웃하고 나서 config.json 파일을 확인해보면 인증 정보(auth)가 삭제되고 docker info에서도 사용자명이 제거됩니다.

 

### 도커 로그인 방법 2 : AccessToken을 이용한 방법

7. 도커 허브 사이트(hub.docker.com)에 로그인
8. 본인 계정 클릭 후 Account Settings를 메뉴를 클릭
9. Security 메뉴의 Personal access tokens 메뉴 클릭
10. Generate new token 클릭
11. 액세스 토큰 설명, 만료 기한, 권한을 설정한 다음에 생성합니다.

![image.png](img/image-248.png)

12. vim을 이용하여 .acess_token 파일을 생성한 다음에 생성한 액세스 토큰을 붙여넣습니다.
13. 다음 명령어를 실행하여 액세스 토큰을 이용한 도커 로그인을 수행합니다.

```java
cat .access_token | docker login --username nemo1107 --password-stdin
```

![image.png](img/image-249.png)

- 실행 결과를 보면 도커 로그인은 성공적으로 수행되었으나 config.json 파일에 암호화되지 않은 패스워드가 저장되어 있다고 경고합니다.

14. config.json 파일을 확인해서 인증 정보가 저장되어 있는지 확인해봅니다.

```java
cat ~/.docker/config.json
```

![image.png](img/image-250.png)

실행 결과를 보면 암호화되지 않은 인증 정보가 저장되어 있습니다.

### 도커 이미지를 파일로 관리

docker image save 명령어는 도커 원본 이미지의 레이어 구조까지 포함한 복제를 수행하여 확장자 tar(Tape ARchiver) 파일로 이미지를 저장합니다.

docker image save 명령어를 사용하는 경우는 다음과 같습니다.

- 도커 허브로부터 이미지를 내려받아 내부망으로 이전하는 경우
- 신규 애플리케이션 서비스를 위해 Dockerfile로 새롭게 생성한 이미지를 저장 및 배포해야 하는 경우
- 컨테이너를 완료(commit)하여 생성한 이미지를 저장 및 배포해야 하는 경우
- 개발 및 수정한 이미지 등

**docker image save 명령어 형식**

```java
docker image save [OPTIONS] <파일명> [image명]
```

**docker image load 명령어 형식**

docker image load 명령어는 docker save로 저장한 tar 파일을 이미지로 불러옵니다.

```java
docker image load [OPTIONS]
```

**docker image save 실습**

mysql:5.7 이미지를 내려받고 확인합니다.

```java
docker pull mysql:5.7
```

![image.png](img/image-251.png)

docker image save 명령어를 이용해서 mysql 이미지를 tar 파일로 저장합니다.

```java
docker image save mysql:5.7 > test-mysql57.tar
ls -lh test-mysql57.tar
```

![image.png](img/image-252.png)

이번에는 tar 명령어를 이용하여 묶인 파일 내용을 확인합니다. 파일의 내용들은 이미지 레이어들의 다이제스트 값으로 만들어진 디렉토리 파일입니다.

```java
tar tvf test-mysql57.tar
```

- t(list), v(verbose), f(file)
    - t: 아카이브의 내용을 나열(list)합니다
    - v: 자세한(verbose) 정보를 출력합니다
    - f: 파일명을 지정합니다. 이 옵션 뒤에는 반드시 파일명이 와야 합니다

![image.png](img/image-253.png)

mysql:5.7 이미지를 삭제합니다.

```java
docker image rm mysql:5.7
```

docker image load 명령어를 이용해서 tar 파일 내용을 이미지로 불러옵니다.

```java
docker image load < test-mysql57.tar
```

![image.png](img/image-254.png)

**docker import를 이용하여 이미지 불러오기**

docker import 명령어를 이용하면 tar 파일을 이미지로 가져올 수 있습니다.

```java
cat test-mysql57.tar | docker import - mysql57:1.0
```

![image.png](img/image-255.png)

docker image save 명령어에서 gzip 옵션을 이용하여 tar 파일의 용량을 줄일수 있습니다.

```java
docker image save mysql:5.7 | gzip > test-mysql57zip.tar.gz
ls -lh test-mysql57zip.tar.gz
```

![image.png](img/image-256.png)

실행 결과를 보면 gzip 파일이 130 메가바이트로써 300 메가바이트 정도 감소되었습니다.

이번에는 셸 스크립트 변수 방식을 이용하여 모든 이미지를 하나의 파일로 저장할 수 있습니다.

```java
docker image save -o all_image.tar $(docker image ls -q)
ls -lh all_image.tar
```

### 도커 이미지 삭제

**도머 이미지 삭제 명렁어 형식**

```java
docker image rm [OPTIONS] {이미지 이름[:태그] | 이미지ID}
```

**도커 이미지 삭제 실습**

삭제 테스트를 위해 ubuntu:14.04 이미지를 내려받습니다.

```java
docker pull ubuntu:14.04
```

docker image rm 명령어를 이용하여 ubuntu:14.04 이미지를 삭제합니다.

```java
docker image rm ubuntu:14.04
```

docker image rm -f 옵션 실습을 위해서 다음과 같이 httpd 이미지를 내려받고 태그를 설정합니다.

```java
docker pull httpd:latest
docker image tag httpd:latest httpd:1.0
docker images httpd
```

![image.png](img/image-257.png)

우선은 일반적인 docker image rm으로 f7d8bafbd9a9(httpd:latest) 이미지를 삭제해봅니다.

```java
docker image rm f7d8bafbd9a9
```

![image.png](img/image-258.png)

실행 결과를 보면 httpd:latest 이미지 파일을 삭제하고자 하였지만, 해당 이미지는 현재 다른 태그가 참조(httpd:1.0)하고 있기 때문에 오류가 발생하였습니다.

위와 같이 관련된 태그까지 모두 삭제하기 위해서는 -f 옵션을 사용해야 합니다.

```java
docker image rm -f f7d8bafbd9a9
```

![image.png](img/image-259.png)

실행 결과를 보면 httpd:latest 이미지뿐만 아니라 httpd:1.0 태그까지도 전부 삭제합니다.

**이미지 전체 삭제**

리눅스의 셸 스크립트 변수 활용 방식을 활용하여 로컬 머신의 도커 이미를 전체 삭제할 수 있습니다.

```java
docker rmi $(docker images -q)
```

- $(docker images -q) : 도커 이미지 정보중에서 이미지 ID만 출력

이번에는 특정 이미지 이름이 포함된 것만 삭제합니다.

```java
docker rmi $(docker imagees | grep debian)
```

이번에는 반대로 특정 이미지 이름이 포함된 것만 제외하고 삭제합니다.

```java
docker rmi $(docker images | grep -v centos)
```

- grep -v : 옵션값으로 매칭된 것과 반대되는 키워드를 캐치합니다.

자주 사용하는 명령어를 전역 alias로 설정하면 편리하게 사용할 수 있습니다.

```java
vim ~/.bashrc
```

```java
alias cexrm='docker rm $(docker ps --filter 'status=exited' -a -q)'
```

```java
source ~/.bashrc
alias
```

![image.png](img/image-260.png)

예를 들어 다음과 같이 httpd 컨테이너를 실행합니다. 그리고 바로 컨테이너를 종료합니다.

```java
docker run -it httpd:latest
docker ps -a
```

![image.png](img/image-261.png)

그 다음에 별칭으로 설정한 cexrm 명령어를 실행합니다.

```java
cexrm
```

![image.png](img/image-262.png)

실행 결과를 보면 실행을 종료한 httpd:latest 컨테이너가 삭제된 것을 볼수 있습니다.

이번에는 httpd:latest 컨테이너를 실행중인 상태에서 이미지를 삭제해보겠습니다.

```java
docker run -d httpd:latest
docker ps -a
```

![image.png](img/image-263.png)

```java
docker image rm httpd:latest
```

![image.png](img/image-264.png)

실행 결과를 보면 httpd:latest 컨테이너가 실행중이기 때문에 삭제할 수 없다는 결과입니다. 이미지를 삭제하기 위해서는 실행중인 컨테이너를 stop 한뒤 rm 명령어를 통해 이미지 삭제가 가능합니다.

**docker image prune 명령어를 이용하여 모든 이미지 삭제**

로컬에 다운로드한 이미지 중 컨테이너가 연결되지 않은 모든 이미지를 제거하기 위해서 docker image prune 명령어를 사용할 수 있습니다.

```java
docker image prune -a
```

- -a 옵션을 사용하면 사용중이 아닌 모든 이미지를 제거합니다.

—filter 옵션을 이용하면 특정 기간이나 이미지 라벨을 지정하여 제거 대상 이미지를 선별할 수 있습니다.

```java
docker image prune -a -f --filter "until=48h"
```

## 3.2.2 도커 컨테이너 명령어

### 컨테이너는 프로세스이다

도커 컨테이너는 도커 이미지를 기반으로 생성한 스냅숏(snapshot)입니다.

- 스냅숏(snapshot)
    - 읽기 전용의 도커 이미지 레이어를 복제한 것
    - 그 위에 읽기/쓰기가 가능한 컨테이너 레이어를 결합한 것이 컨테이너가 됩니다.
- 컨테이너는 격리된 공간에서 프로세스가 동작하는 기술입니다.

도커 컨테이너의 PID 1번 프로세스도 init 프로세스인지 확인해봅니다.

우선은 호스트 머신에서 실행중인 셸 프로세스 ID를 확인해봅니다.

```java
echo $$
```

![image.png](img/image-265.png)

이번에는 centos 8 버전 이미지 다운로드 후에 bash 모드로 접속합니다.

```java
docker run -it centos:8 bash
root@1bbfb4f8e13d # echo $$
```

![image.png](img/image-266.png)

위 실행 결과를 보면 컨테이너 안에서 셸 프로세스 ID 조회시 1이 출력된 것을 볼수 있습니다.

컨테이너에서 빠져나와서 다른 터미널에서 실행중인 PID를 조회해봅니다.

```java
ps -ef | grep 1058732
```

![image.png](img/image-267.png)

/proc 디렉토리와 하위 네임 스페이스(ns) 경로를 확인해봅니다. 

```java
cd /proc/1058732/
ls -l
```

![image.png](img/image-268.png)

호스트 운영체제의 PID 1번과 현재 호스트에서 실행중인 셸 프로세스를 비교합니다.

```java
sudo ls -l /proc/1/ns
```

![image.png](img/image-269.png)

위 실행 결과는 PID 1번(init 프로세스)의 네임 스페이스 정보를 출력합니다. 출력된 결과는 /proc/1/ns 디렉토리 내에 있는 **각 네임스페이스의 심볼릭 링크(symbolic link)**입니다.

네임 스페이스는 리눅스 컨테이너 및 격리된 환경을 만들기 위해 사용됩니다. PID 1번은 init 또는 systemd 프로세스로, 일반적으로 시스템의 최상위 프로세스입니다. PID 1에 속한 네임스페이스들은 보통 호스트 OS의 기본 네임스페이스이며, 모든 프로세스가 기본적으로 공유합니다.

<aside>
💡

네임스페이스(Namespace)

네임스페이스는 리눅스 커널이 제공하는 프로세스 격리 기술 중 하나로, 특정 리소스를 개별 프로세스 그룹만 볼 수 있도록 논리적으로 분리하는 기능입니다.

네임 스페이스를 활용하면 프로세스들이 독립적인 환경에서 실행될 수 있으며, 이를 통해 컨테이너 같은 가상화 기술을 구현할 수 있습니다.

</aside>

프로세스 1115418 번의 네임 스페이스를 조회해봅니다. 1115418 프로세스는 셸 프로세스ID입니다.

```java
sudo ls -l /proc/1115418/ns
```

![image.png](img/image-270.png)

실행 결과를 보면 1번 프로세스의 네임 스페이스와 동일합니다. 동일한 이유는 셸 프로세스가 네임스페이스를 따로 변경하지 않았기 때문입니다. 즉, 셸 프로세스는 시스템이 기본적으로 제공하는 네임스페이스(PID1 네임스페이스)를 그대로 사용하기 때문입니다.

**네임 스페이스가 동일하다는 의미**

리눅스 시스템에서 새 프로세스 생성시 기본적으로 부모 프로세스의 네임스페이스를 그대로 상속합니다.

- PID 1(init/systemd)은 부팅시 생성된 첫번째 프로세스로, 시스템 전체의 기본 네임스페이스를 사용합니다.
- 사용자가 터미널을 열어서 실행하는 셸 프로세스(PID 1115418)은 일반적으로 systemd(PID 1)의 자식 프로세스로 실행합니다.
- 따라서, 셸 프로세스는 PID 1과 동일한 네임스페이스를 공유합니다.

**네임스페이스가 다르게 설정되는 경우**

네임스페이스가 기본적으로 상속되지만, 특정 조건에서는 다를 수 있습니다.

15. Docker 및 컨테이너 내부에서 실행되는 프로세스
    - 컨테이너 내부의 bash 프로세스는 PID 1과 다른 네임스페이스를 가짐
    - 실행한 결과를 보면 호스트 머신의 PID 1 네임 스페이스와 다른 값을 가집니다.

```
docker run -it --rm centos:8 sh
ls -l /proc/1/ns
```
![image.png](img/image-271.png)

16. unshare 명령어로 새로운 네임스페이스 생성
17. setns를 사용하여 다른 네임스페이스로 이동

정리해보면 docker run ~ 수행시 PID 네임스페이스 커널 기능을 통해 시스템의 1번 프로세스의 PID를 공유하고 그 하위로 프로세스를 격리합니다. 이렇게 격리된 프로세스를 루트로 변경하는 chroot 커널 기능을 통해 독립된 1번 PID를 갖게 되고, 컨테이너 동작시 피룡한 자원에 대한 할당은 cgroups 커널 기능을 통해 이루어집니다.

### 컨테이너 실행

컨테이너를 생성하기 위해서 docker create 명령어를 사용합니다. 해당 명령어를 이용하여 컨테이너 생성시 시작하지는 않은 상태 입니다.

```java
docker create -it --name container-test1 ubuntu:14.04
```

![image.png](img/image-272.png)

![image.png](img/image-273.png)

실행 결과를 보면 ubuntu:14.04 컨테이너의 상태가 Created입니다. 이 상태는 컨테이너가 생성은 되어 있지만 실행은 아닌 상태입니다.

생성한 컨테이너를 실행시키기 위해서는 `docker start` 명령어를 사용해야 합니다.

```java
docker start container-test1
```

![image.png](img/image-274.png)

실행 결과를 보면 container-test1 컨테이너의 상태가 `Up` 이 되었습니다. 이는 실행중인 상태입니다.

이번에는 실행중인 컨테이너로 쉘 접속하기 위해서 `docker attach` 명령어를 사용하겠습니다.

```java
docker attach container-test1
```

![image.png](img/image-275.png)

실행 결과를 보면 정상적으로 container-test1 컨테이너에 쉘 접속하였습니다. docker attach 명령어를 사용하여 컨테이너에 접속해서 단순 조회하는 경우에 유용합니다.

컨테이너를 빠져나온 다음에 종료된 컨테이너를 삭제해보겠습니다.

```java
exit
docker ps -a
docker rm container-test1
```

![image.png](img/image-276.png)

![image.png](img/image-277.png)

일반적으로 docker create → docker start 명령어가 아닌 이 둘을 결합한 기능인 `docker run` 명령어를 사용하여 컨테이너를 실행합니다.

```java
docker run -it --name container-test1 ubuntu:14.04 bash
```

![image.png](img/image-278.png)

이번에는 컨테이너 실행시 호스트 네임을 출력하도록 합니다.

```java
docker run -it --name container-test1 ubuntu:14.04 hostname
```

![image.png](img/image-279.png)

실행 결과를 보면 hostname을 출력하고 컨테이너가 실행을 종료합니다. 종료된 컨테이너를 삭제하기 위해서는 별도로 제거해주어야 합니다.

```java
docker rm container-test1
```

docker run 명령어 실행시 로컬 머신에서 이미지가 없더라도 이미지를 도커 허브로부터 내려받은 다음에 생성 및 실행합니다. 그리고 컨테이너 실행 시작시 별도의 명령어를 전달하여 실행하도록 할 수 있습니다. 즉, docker run 명령의 기능을 정리하면 다음과 같습니다. 다음 공식에서 pull과 command는 선택적인 옵션입니다.

```java
docker run = [pull] + create + create + [command]
```

**docker run 옵션**

| 옵션                                      | 설명                                                                                                 |                                                                                   |
| ----------------------------------------- | ---------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| -i, —interactive                          | 컨테이너가 실행되는 동안 입력받을 수 있도록 합니다.                                                  |                                                                                   |
| -t                                        | 컨테이너에 가상 터미널을 할당합니다.                                                                 |                                                                                   |
| -d, —detach=true                          | 백그라운드에서 실행합니다.                                                                           |                                                                                   |
| —name                                     | 컨테이너 이름 설정합니다.                                                                            |                                                                                   |
| —rm                                       | 컨테이너 종료시 자동으로 컨테이너를 제거합니다.                                                      |                                                                                   |
| —restart                                  | 컨테이너 실행 실패시 재시작합니다. always 옵션이면 성공할때까지 계속 실행합니다.                     |                                                                                   |
| —env                                      | 컨테이너의 환경 변수를 설정합니다.                                                                   |                                                                                   |
| -v, —volume=호스트경로:컨테이너경로       | 호스트 경로와 컨테이너 경로의 공유 볼룸을 설정합니다. (Bind mount)                                   |                                                                                   |
| -h                                        | 컨테이너의 호스트명 지정(따로 지정하지 않으면 컨테이너 ID가 호스트명으로 등록된다)                   |                                                                                   |
| -p [Host 포트]:[Container 포트], —publish | 호스트 포트와 컨테이너 포트를 연결합니다.                                                            |                                                                                   |
| -P, —publish-all=[true                    | false]                                                                                               | 컨테이너 내부에 열려 있는 모든 포트를 호스트의 랜덤한 포트에 자동으로 매핑합니다. |
| —link=[container:container_id]            | 동일한 호스트에서 다른 컨테이너와 연결하는 설정으로 IP가 아니라 컨테이너 이름을 이용해서 통신합니다. |                                                                                   |

### SQL 테스트를 위한 개발팀의 요청으로 MySQL 5.7 실행

18. mysql:5.7 이미지를 내려받습니다.

```java
docker pull --platform linux/amd64 mysql:5.7
```

- 현재 실행중인 환경이 mac m1 amd64를 사용하고 있기 때문에 이미지를 내려받는 경우 —platform 옵션을 이용하여 linux/amd64를 설정합니다.

19. 이미지를 정상적으로 내려받았는지 확인합니다.

```java
docker images | grep mysql
```

![image.png](img/image-280.png)

20. docker run 명령어를 이용해서 mysql 컨테이너를 실행합니다.

```java
docker run --name mysql-container -e MYSQL_ROOT_PASSWORD=root -d -p 33306:33306 -it mysql:5.7
```

![image.png](img/image-281.png)

21. mysql-container로 터미널 접속합니다.

```java
docker exec -it mysql-container bash
```

![image.png](img/image-282.png)

22. mysql 컨테이너로 터미널 접속한 상태에서 os-release를 출력합니다.

```java
mysql $ cat /etc/os-release
```

![image.png](img/image-283.png)

/etc/os-release 파일의 역할은 다음과 같습니다.

- 리눅스 배포판 정보 제공
- MySQL이 실행되는 베이스 이미지가 무엇인지 확인이 가능합니다.

위 실행 결과 분석은 다음과 같습니다.

- mysql 컨테이너의 기반 운영체제는 Oracle Linux Server 7.9입니다.
- ID_LIKE의 값이 “fedora”이기 때문에 패키지 관리 시스템이 yum 또는 dnf를 사용합니다.

23. mysql 루트 계정으로 접속

```java
mysql $ mysql -u root -p
```

![image.png](img/image-284.png)

24. 데이터베이스 스키마를 조회

```java
show databases;
```

![image.png](img/image-285.png)

25. “dockerdb” 데이터베이스 스키마 생성

```java
create database dockerdb;
```

![image.png](img/image-286.png)

26. mysql 접속 연결을 해제한 뒤에 mysql-container 컨테이너에서 dockerdb 데이터베이스가 생성되었는지 확인해봅니다.

```java
exit
ls -l /var/lib/mysql/
```

![image.png](img/image-287.png)

실행 결과를 보면 mysql 라이브러리 디렉토리에 dockerdb 디렉토리가 생성되었습니다.

27. mysql 컨테이너의 터미널을 빠져나온 후에 컨테이너를 중지시킵니다.

```java
docker stop mysql-container
```

![image.png](img/image-288.png)

28. docker start 명령을 통해서 중지된 mysql-container를 다시 실행시킬 수 있습니다.

```java
docker start mysql-container
```

![image.png](img/image-289.png)

29. mysql-container 컨테이너의 IP 주소를 조회해봅니다.

```java
docker inspect mysql-container | grep IPAddress
```

![image.png](img/image-290.png)

실행 결과 mysql-container 컨테이너의 내부 IP 주소는 “172.17.0.2”입니다.

30. 컨테이너를 중지하고 삭제하여 실습을 마무리합니다.

```java
docker stop mysql-container
docker rm mysql-container
```

### 컨테이너 모니터링 도구 cAdvisor 컨테이너 실행

- 서비스 운영하면서 필요한 Metric(CPU, 메모리 사용율, 네트워크 트래픽 등)을 모니터링하면서 특이사항이 있으면 대응하기 위해서 모니터링을 수행합니다.
- 그런데 컨테이너 환경에서 기존 모니터링 도구로는 컨테이너 모니터링 진행이 어렵습니다.
- 이러한 문제를 해결하기 위해서 구글에서 제공하는 cAdvisor(container Advisor)를 많이 사용합니다.

31. docker run 명령어를 이용해서 cadvisor 컨테이너를 실행합니다.

```java
docker run \
	--volume=/:/rootfs:ro \
	--volume=/var/run:/var/run:rw \
	--volume=/sys:/sys:ro \
	--volume=/var/lib/docker/:/var/lib/docker:ro \
	-p 9559:8080 \
	-d \
	--name=cadvisor \
	gcr.io/cadvisor/cadvisor:latest
```

![image.png](img/image-291.png)

32. 브라우저를 이용해서 접근을 시도합니다.

```java
http://3.35.207.14:9559/
```

![image.png](img/image-292.png)

![image.png](img/image-293.png)

![image.png](img/image-294.png)

![image.png](img/image-295.png)

위 메뉴에서 docker container 메뉴를 클릭하면 특정 컨테이너의 CPU/메모리 사용량을 모니터링할 수 있습니다.

33. 실습을 마무리하기 위해서 컨테이너를 종료합니다.

```java
docker stop cadvisor
docker rm cadvisor
```

### 웹 서비스 실행을 위한 Nginx 컨테이너 실행

34. nginx:1.18 이미지를 내려받습니다.

```java
docker pull nginx:1.18
```

![image.png](img/image-296.png)

35. docker run 명령어를 이용해서 nginx 컨테이너를 실행합니다.

```java
docker run --name webserver1 -d -p 8001:80 nginx:1.18
```

![image.png](img/image-297.png)

![image.png](img/image-298.png)

36. 호스트의 8001 포트가 열린것을 확인합니다.

```java
sudo netstat -nlp | grep 8001
```

- -n : 숫자 형식으로 IP 주소와 포트 번호 출력
- -l : 수신 대기중인 소켓만 출력
- -p : 해당 소켓을 사용하는 프로세스 정보 출력

![image.png](img/image-299.png)

37. curl 명령어를 이용하여 접속 테스트 해봅니다.

```java
curl localhost:8001
```

![image.png](img/image-300.png)

38. 컨테이너 리소스 사용량을 실시간으로 확인합니다.

```java
docker stats webserver1
```

![image.png](img/image-301.png)

39. 컨테이너의 실행 중인 프로세스를 표시합니다.

```java
docker top webserver1
```

![image.png](img/image-302.png)

40. docker logs 명령어를 이용해서 nginx 컨테이너의 접근 로그를 확인합니다.
    - -f : 실시간 옵션

```
docker logs -f webserver1
```

- [http://3.35.207.14:8001](http://3.35.207.14:8001) 경로로 요청을 날려봅니다.

![image.png](img/image-303.png)

- 실행 결과를 보면 크롬 브라우저에서 접근한 것이 로깅되어 있습니다.

41. docker cp 명령어를 통해서 nginx 컨테이너 내부의 index.html 파일 경로에 새로운 index.html 파일을 복사합니다.

index.html

```java
<h1> Hello, Jpub Docker. </h1>
```

도커 명령어

```java
docker cp index.html webserver1:/usr/share/nginx/html/index.html
```

![image.png](img/image-304.png)

42. curl 명령어로 nginx 서버에 요청을 날려봅니다.

```java
curl localhost:8001
```

![image.png](img/image-305.png)

실행 결과를 보면 우리가 작성한 index.html 파일의 내용을 렌더링하였습니다.

43. docker pause 명령어를 이용해서 컨테이너를 일시 중단시킵니다.

```java
docker pause webserver1
```

![image.png](img/image-306.png)

실행 결과를 보면 webserver1 컨테이너의 상태가 Up (Paused)입니다.

44. 이번에는 docker unpause 명령어를 이용해서 컨테이너를 일시 중단을 해제합니다.

```java
docker unpause webserver1
```

![image.png](img/image-307.png)

45. 현재 실행중인 webserver1 컨테이너의 PID를 확인합니다.

```java
ps -ef | grep 8001
```

![image.png](img/image-308.png)

실행 결과를 보면 webserver1 컨테이너의 PID는 1128783입니다.

46. webserver1 컨테이너를 재시작합니다.

```java
docker restart webserver1
```

47. 다시 webserver1의 PID를 확인합니다.

```java
ps -ef | grep 8001
```

![image.png](img/image-309.png)

실행 결과를 보면 재시작한 webserver1 컨테이너의 PID는 1129918 입니다.

위 예제를 통하여 알수 있는 사실은 컨테이너가 docker pause 명령어로 일시 중지 되었다가 docker unpause로 일시 중지가 해제되어도 컨테이너의 PID는 변경되지 않지만, docker restart와 같이 재시작하는 경우 컨테이너의 PID가 변경됩니다.

이는 컨테이너를 재시작하는 것은 기존 컨테이너 프로세스를 정지하고, 새로운 컨테이너 프로세스를 시작하는 것을 의미합니다. 컨테이너 동작에는 영향을 주지 않고 호스트의 PID만 변경됩니다.

48. webserver 컨테이너를 삭제합니다.

```java
docker stop webserver1
docker rm webserver1
```

### 파이썬 프로그래밍 환경을 컨테이너로 제공

49. 파이썬 코드 기반의 로또 프로그램을 작성합니다.

```java
vim py_lotto.py
```

py_lotto.py

```python
from random import shuffle
from time import sleep
gamenum = input('로또 게임 횟수를 입력하세요: ')
for i in range(int(gamenum)):
    balls = [x+1 for x in range(45)]
    ret = []
    for j in range(6):
        shuffle(balls)
        number = balls.pop()
        ret.append(number)
    ret.sort()
    print('로또번호[%d]: ' %(i+1), end='')
    print(ret)
    sleep(1)
```

50. 파이썬 컨테이너 실행수 py_lotto.py 샘플 코드를 복사합니다.

```java
docker run -it -d --name=python_test -p 8900:8900 python
docker cp py_lotto.py python_test:/
```

![image.png](img/image-310.png)

51. 파이썬 컨테이너로 배시쉘로 접속

```java
docker exec -it python_test bash
```

52. 파이썬이 설치되어 있는지 확인하기 위해서 python으로 접속해봅니다.

```java
root # python
```

![image.png](img/image-311.png)

53. 파이썬 관련 도구를 확인합니다.

```java
pip list
```

![image.png](img/image-312.png)

54. 파이썬 컨테이너에 설치된 파이썬 모듈을 체크합니다.

```java
python -c 'help("modules")'
```

![image.png](img/image-313.png)

- -c : python 명령어를 실행

55. 외부에서 파이썬 컨테이너 코드를 실행합니다.

```java
docker exec -it python_test python /py_lotto.py
```

![image.png](img/image-314.png)

## 3.2.3 도커 볼륨 활용

도커 볼륨 기능을 활용하면 컨테이너에서 발생한 데이터를 영속적으로 저장할 수 있습니다.

### 도커 볼륨 타입

**volume**

- 도커에서 권장하는 방법. docker volume create {볼륨 이름} 명령어를 통해서 볼륨 생성 가능합니다.
- 도커 볼륨은 도커 명령어(docker volume)를 통해서 관리할 수 있습니다.
- 여러 컨테이너 간에 안전하게 공유 가능합니다.
- 볼륨 드라이버를 이용해서 원격 호스트 및 클라우드 환경에 볼륨 내용을 저장하고 암호화 가능합니다.
- 새 볼륨 영역에 데이터를 미리 채우고 컨테이너를 연결하면 컨테이너 안에서 바로 데이터 사용이 가능합니다.

**volume 실습**

56. my-appvol-1 라는 이름의 볼륨을 생성합니다.

```java
docker volume create my-appvol-1
docker volume ls
```

![image.png](img/image-315.png)

57. my-appvol 볼륨을 검사합니다. 볼륨이 올바르게 생성되었고 마운트되었는지 확인하는데 사용합니다.

```java
docker volume inspect my-appvol-1
```

![image.png](img/image-316.png)

실행 결과를 보면 마운트 경로가 /var/lib/docker/volumes/my-appvol-1/_data 디렉토리 경로에 설정되었습니다.

58. ubuntu:20.04 컨테이너 실행시 my-appvol-1 볼륨을 지정합니다.

```java
docker run -d --name vol-test1 --mount source=my-appvol-1,target=/app ubuntu:20.04
```

![image.png](img/image-317.png)

도커 컨테이너 실행시 -v 옵션을 이용해서 볼륨 지정이 가능합니다.

```java
docker run -d --name vol-test2 -v my-appvol-1:/var/log ubuntu:20.04
```

사전에 docker volume create 명령어를 이용해서 볼륨을 먼저 생성하지 않아도 호스트 볼륨 이름을 쓰면 자동생성됩니다.

```java
docker run -d --name vol-test3 -v my-appvol-2:/var/log ubuntu:20.04
```

59. 도커 볼륨 리스트를 조회해봅니다.

![image.png](img/image-318.png)

60. vol-test1 컨테이너를 분석해서 볼륨 마운트된 것이 무엇인지 확인합니다.

```java
docker inspect --format="{{ .Mounts }}" vol-test1
```

![image.png](img/image-319.png)

실행 결과를 보면 my-appvol-1 볼륨이 설정되어 있습니다.

61. 이번에는 my-appvol-1 볼륨을 제거합니다.

```java
docker volume rm my-appvol-1
```

![image.png](img/image-320.png)

실행 결과를 보면 현재 연결된 컨테이너가 존재하기 때문에 볼륨을 삭제할 수 없습니다.

62. 연결된 컨테이너 제거 후 볼륨을 삭제합니다.

```java
docker stop vol-test1 vol-test2
```

```java
docker rm vol-test1 vol-test2
```

```java
docker volume rm my-appvol-1
```

**bind mount**

- 도커 볼륨 기법에 비해 사용이 제한적입니다.
- **호스트 파일 시스템 절대경로: 컨테이너 내부 경로** 를 직접 마운트하여 사용합니다.
    - 예: ~/logs:/var/log ⇒ 컨테이너의 /var/log 경로와 홈 디렉토리의 logs 디렉토리와 마운트합니다.
- 컨테이너에서 볼륨 경로에 파일이나 디렉토리를 생성하게 되면 호스트 운영체제의 소유자 권한으로 생성됩니다.
- 호스트 운영체제의 사용자가 파일이나 디렉토리를 생성하면 호스트 사용자 권한으로 연결되고, 파일이나 디렉토리가 존재하지 않으면 자동 생성됩니다. 이때 자동 생성되는 디렉토리는 루트 사용자 소유가 됩니다.
- 컨테이너 실행시 지정하여 사용하고, 컨테이너 제거시 bind mount는 해제되지만, 호스트 디렉토리는 유지됩니다.

**bind mount 실습**

63. bind mount할 디렉토리를 생성합니다.

```java
mkdir ~/target
```

64. centos 컨테이너 실행시 target 디렉토리를 대상으로 bind mount를 설정합니다.

```java
docker run -d -it --name bind-test1 \
--mount type=bind,source="$(pwd)"/target,target=/var/log \
centos:8
```

-v 옵션을 이용해서 미리 생성한 target 디렉토리와 bind mount 지정합니다.

```java
docker run -d -it --name bind-test2 \
-v "$(pwd)"/target:/var/log \
centos:8
```

사전에 생성하지 않은 디렉토리와 bind mount 지정합니다.

```java
docker run -d -it --name bind-test3 \
-v ~/target2:/var/log \
centos:8
```

사전에 생성하지 않은 디렉토리에 읽기 전용 및 읽기 쓰기 bind mount 지정

```java
docker run -d -it --name bind-test4 \
-v ~/target_ro:/app1:ro \
-v ~/target_rw:/app2:rw \
centos:8
```

65. 4개의 컨테이너 실행후 bind mount 지정한 디렉토리의 권한 정보를 확인해봅니다.

```java
ls -l
```

![image.png](img/image-321.png)

위 실행 결과를 보면 사전 생성한 target 디렉토리는 ec2-user이고, -v 옵션으로 지정한 경로로 설정한 디렉토리들(target2, target_ro, target_rw)는 루트 사용자 소유입니다.

66. bind-test2 컨테이너의 바인드 마운트된 경로를 조회합니다.

```java
docker inspect --format="{{ .HostConfig.Binds }}" bind-test2
```

![image.png](img/image-322.png)

```java
docker inspect --format="{{ .HostConfig.Binds }}" bind-test4
```

![image.png](img/image-323.png)

**tmpfs mount**

- 이 방법은 호스트 메모리에서만 지속되고, 컨테이너가 중지되면 tmpfs 마운트가 제거되어 컨테이너 내부의 파일 시스템에 기록된 파일은 유지되지 않습니다.
- 컨테이너 실행할때 tmpfs mount 지정해서 사용하고, 컨테이너를 제거할 때 자동 해제됩니다.

**tmpfs mount 실습**

67. httpd 컨테이너 실행할 때 —mount 옵션을 사용하여 tmpfs mount 설정합니다.

```java
docker run -d -it --name tmpfs-test1 \
--mount type=tmpfs,destination=/var/www/html \
httpd:2
```

—tmpfs 옵션을 사용하여 tmpfs mount 설정합니다.

```java
docker run -d -it --name tmpfs-test2 \
--tmpfs /var/www/html \
httpd:2
```

68. tmpfs 마운트된 컨테이너를 조회합니다.

```java
docker inspect --format="{{ .HostConfig.Tmpfs }}" tmpfs-test2
```

![image.png](img/image-324.png)

### 도커 볼륨 활용

**데이터베이스의 데이터 지속성 유지 실습**

69. mysql 데이터베이스 데이터를 저장하기 위한 볼륨을 생성합니다.

```java
docker volume create mysql-data-vol
docker volume ls
```

![image.png](img/image-325.png)

70. mysql 컨테이너 실행 시 이전 단계에서 생성한 볼륨을 설정합니다.

```java
docker run -it -d --name=mysql-vtest \
-e MYSQL_ROOT_PASSWORD=root \
-e MYSQL_DATABASE=dockertest \
-v mysql-data-vol:/var/lib/mysql \
mysql:5.7
```

71. MySQL 컨테이너에 접속합니다.

```java
docker exec -it mysql-vtest bash
```

![image.png](img/image-326.png)

72. 컨테이너에서 root 계정으로 접속합니다.

```java
mysql -u root -p
{패스워드 입력}
```

![image.png](img/image-327.png)

73. 데이터베이스 스키마들을 조회해봅니다.

```java
show databases;
```

![image.png](img/image-328.png)

실행 결과를 보면 컨테이너 실행시 환경변수로 설정한 dockertest에 대한 스키마가 존재합니다.

74. dockertest 스키마를 사용하고 테이블과 데이터를 만들어봅니다.

```java
use dockertest;
create table mytab(c1 int, c2 char);
insert into mytab values(1, 'a');
select * from mytab;
```

![image.png](img/image-329.png)

실행 결과를 보면 정상적으로 테이블을 생성하고 데이터가 삽입되었습니다. 우리는 이 데이터가 컨테이너가 제거되고 추후에 다시 컨테이너가 생성되어도 데이터는 유지되어야 할 것입니다.

75. mysql 데이터베이스로부터 빠져나옵니다.

```java
exit
```

![image.png](img/image-330.png)

76. 다음 경로에 위치한 디렉토리의 파일 구성을 확인해봅니다.

```java
ls /var/lib/mysql/dockertest/
```

![image.png](img/image-331.png)

- mytab.frm 파일은 테이블의 스키마 구조 정보를 저장하는 파일입니다.
    - 테이블 칼럼 정보, 인덱스, 제약 조건 등의 스키마 정의를 포함하고 있음
- mytab.ibd 파일은 테이블의 실제 데이터와 인덱스를 저장하는 파일입니다.

위 실행 결과를 통해서 mysql의 dockertest 스키마에 mytab 테이블에 대한 스키마 정보와 데이터가 파일 형태로 저장되어 있는 것을 확인할 수 있습니다.

77. docker inspect 명령어를 통해서 mysql-vtest 컨테이너에 마운트된 데이터를 확인해봅니다.

```java
docker inspect --format="{{ .Mounts }}" mysql-vtest
```

![image.png](img/image-332.png)

실행 결과를 보면 mysql-data-vol 볼륨이 마운트되어 있습니다.

78. mysql-data-vol 볼륨이 실제 저장되어 있는 디렉토리로 이동하여 데이터 정보를 확인해봅니다.

```java
ls -l /var/lib/docker/volumes/mysql-data-vol/_data/dockertest/
```

![image.png](img/image-333.png)

실행 결과를 보면 mysql 컨테이너의 mysql 데이터베이스에서 생성한 테이블과 데이터 정보 파일이 저장되어 있습니다. 

79. 만약 mysql 컨테이너가 장애가 발생하여 정지한 후 해당 컨테이너를 제거했다고 가정해봅니다. 그리고 새로운 컨테이너를 생성하고 mysql-data-vol 볼륨을 연결하여 데이터가 유지되었는지 확인해봅니다.

```java
docker stop mysql-vtest
```

![image.png](img/image-334.png)

정지한 컨테이너를 삭제합니다.

```java
docker rm mysql-vtest
```

그리고 다시 mysql-vtest 컨테이너를 재생성하여 실행합니다.

```java
docker run -it -d --name=mysql-vtest \
-e MYSQL_ROOT_PASSWORD=root \
-e MYSQL_DATABASE=dockertest \
-v mysql-data-vol:/var/lib/mysql \
mysql:5.7
```

![image.png](img/image-335.png)

mysql 컨테이너에 배시 쉘로 접속합니다.

```java
docker exec -it mysql-vtest bash
```

![image.png](img/image-336.png)

mysql 데이터베이스로 접속한 다음에 dockertest 스키마 안에 있는 mytab 테이블과 데이터가 여전히 존재하는지 확인합니다.

```java
mysql -u root -p 
```

```java
show databases;
```

![image.png](img/image-337.png)

```java
use dockertest
show tables;
select * from mytab;
```

![image.png](img/image-338.png)

실행 결과를 보면 여전히 데이터가 유지된 것을 볼수 있습니다.

이 실습을 통해서 볼륨을 이용해서 데이터를 영속적으로 유지하는 방법에 대해서 학습하였습니다.

**실습: 웹 서비스의 로그 정보 보호 및 분석을 위한 바인드 마운트 설정**

Nginx의 acess.log 파일을 통해 장애 발생시 로그 파일을 이용해서 장애 정보를 파악하거나 실시간 접근 로그를 분석할 수 있습니다.

호스트 운영체제에서 바인드 마운트를 통해 수집된 access.log에 대해 셸 스크립트에서 주로 사용되는 awk를 이용하여 로그 분석을 할 수 있습니다.

80. 호스트 운영체제에서 nginx 로그 파일을 저장할 디렉토리르 생성합니다.

```java
mkdir nginx-log
```

81. nginx 컨테이너를 실행합니다.

```java
docker run -d -p 8001:80 \
-v ~/nginx-log:/var/log/nginx \
nginx:1.19
```

![image.png](img/image-339.png)

82. nginx-log 디렉토리의 내용을 확인합니다.

```java
ls -l ~/nginx-log
```

![image.png](img/image-340.png)

83. nginx 서버에 요청을 날려서 액세스 로그를 남깁니다.

```java
curl http://localhost:8001
```

![image.png](img/image-341.png)

84. tail 명령어를 이용해서 실시간으로 접근되는 로그 정보를 수집해봅니다.

```java
tail -f nginx-log/access.log
```

![image.png](img/image-342.png)

실행 결과를 보면 2번의 요청이 들어온 것을 확인 가능합니다.

<aside>
💡

nginx 로그 패턴

IP(1)-(2)-(3) [날짜/시간(4) +0900](5) “POST(6) /*(7) HTTP(8) 200(9) 사이즈(10)

</aside>

85. 지정한 날짜/시간 내에 기록된 IP 정보를 내림차순으로 카운트하여 횟수와 IP 주소 출력합니다.(예: 01/Mar/2021:12:32:37)

```java
awk '$4>"[로그에 기록된 날짜, 시간]" && $4<"[로그에 기록된 날짜, 시간]"' access.log |
awk '{ print $1 }' | sort | uniq -c | sort -r | more
```

- awk를 이용하여 4번째 필드($4)가 특정 시간 범위에 해당하는 행만 출력합니다.
- $4는 일반적인 Apache 포맷에서 [날짜/시간] 필드입니다.
- 4번째 시간 필드가 로그에 기록된 날짜 및 시간 2개의 사이에 위치한 행만 출력합니다.
- sort : 정렬하여 같은 IP가 모이도록 함
- uniq -c : 중복된 IP 개수를 세서 출력
- sort -r : 많은 요청한 IP 순으로 내림차순 정렬
- more : more 명령어에 입력으로 들어가서 출력하도록 함

```java
awk '$4>"[31/Jan/2025:03:07:33]" && $4<"[31/Jan/2025:05:07:33]"' access.log |
awk '{ print $1 }' | sort | uniq -c | sort -r | more
```

![image.png](img/image-343.png)

access.log는 2개의 로그가 존재하고 시간이 3시 7분 ~ 5시 7분까지 범위에 있는 로그들을 탐색하고 출력합니다. 실행 결과를 보면 172.17.0.1 IP 주소가 2번 요청하였습니다.

첫번째 awk의 결과는 다음과 같습니다. 

```java
awk '$4>"[31/Jan/2025:03:07:33]" && $4<"[31/Jan/2025:05:07:33]"' access.log | more
```

![image.png](img/image-344.png)

실행 결과를 보면 원본 로그 그대로 출력됩니다. 이후 두번째 awk를 통해서 IP 주소 필드($1)를 추출하여 출력합니다.

<aside>
💡

AWS의 CloudWatch, ElasticSearch 등을 이용할 때도 이와 같은 패턴을 숙지하면 로그 정보 파악과 분석이 용이합니다.

</aside>

**실습: 컨테이너 간에 데이터 공유를 위한 데이터 컨테이너 만들기**

여러 컨테이너가 데이터를 공유해서 사용할 수 있도록 데이터 전용 컨테이너를 생성(docker run으로 실행하는 것이 아닌 docker create로 생성만 함)하고 공유 볼륨을 여러 컨테이너에 연결합니다. 데이터 컨테이너를 만들고 컨테이너 내의 데이터베이스 백업, 복구 및 마이그레이션 등의 작업에 활용할 수 있습니다.

86. ubuntu 컨테이너 생성시 data-volume이라는 이름의 디렉토리를 볼륨 경로로 설정합니다.

```java
docker create -v /data-volume --name=datavol ubuntu:18.04
```

![image.png](img/image-345.png)

![image.png](img/image-346.png)

실행 결과를 보면 datavol 컨테이너의 상태가 Up이 아닌 Created 상태입니다.

87. 새로운 ubuntu 컨테이너를 실행할 때 `—volumes-from` 옵션을 이용해서 데이터 전용 컨테이너를 설정합니다. 

```java
docker run -it --volumes-from datavol ubuntu:18.04
```

- —volumes-from으로 지정된 컨테이너에는 모두 동일한 이름의 디렉토리가 생성됩니다.

88. 다음 명령어를 실행하여 에코 명령어를 실행한 결과를 텍스트 파일에 저장합니다.

```java
echo 'testing data container' > /data-volume/test-volume.txt
```

![image.png](img/image-347.png)

89. test-volume.txt 파일의 내용을 출력합니다.

```java
cat /data-volume/test-volume.txt
```

![image.png](img/image-348.png)

접속중인 ubuntu 컨테이너에서 나옵니다.

```java
exit
```

![image.png](img/image-349.png)

90. docker ps 명령어를 이용하여 현재 ubuntu 컨테이너들의 상태를 확인합니다.

![image.png](img/image-350.png)

실행 결과를 보면 8c4 컨테이너는 Exited 상태이고, 416 컨테이너는 데이터 전용 컨테이너로써 여전히 Created 상태입니다.

91. 다시 ubuntu 컨테이너를 실행하여 data-volume 디렉토리 안에 데이터를 작성해봅니다.

```java
docker run -it --volumes-from datavol ubuntu:18.04
root# echo 'testing data container2' > /data-volume/test-volume2.txt
root# ls -l /data-volume/
exit
```

![image.png](img/image-351.png)

실행 결과를 보면 여전히 data-volume 디렉토리에는 test-volume.txt 파일이 존재합니다.

92. docker ps 명령어로 데이터 전용 컨테이너의 컨테이너 ID를 확인하고 해당 컨테이너의 볼륨 이름을 확인합니다.

```java
docker ps -a
docker inspect --format "{{ .Mounts }}" 4164931648ba
```

![image.png](img/image-352.png)

- 실행 결과를 보면 data-volume 디렉토리에 설정된 볼륨 이름이 **db0f198cee0a2fe37c2a063ca093d93c9feb47c10c85763db7b844bc501b0601** 입니다.

93. 호스트 운영체제의 root 유저로 접속하여 볼륨의 데이터를 직접 확인해봅니다.

```java
ls -l /var/lib/docker/volumes/db0f198cee0a2fe37c2a063ca093d93c9feb47c10c85763db7b844bc501b0601/_data
```

![image.png](img/image-353.png)

실행 결과를 보면 볼륨에는 컨테이너에 저장된 텍스트 데이터가 유지되고 있습니다.

위와 같은 실습을 통해서 호스트 운영체제의 볼륨 연결 디렉토리(/var/lib/docker/volumes/../_data)가 다른 서버와 NFS(Network File System)으로 연결된 경로라면 자동으로 다른 서버 쪽으로 데이터가 백업되어 안정적인 데이터 관리를 할수 있습니다.

**실습: 실무에서 유용한 볼륨 활용** 

nginx 웹서비스를 하는 컨테이너를 개발한다고 가정합니다. Dockerfile을 이용한 이미지 개발시 개발팀으로부터 전달받은 웹 소스를 Nginx 컨테이너 내부의 웹 기본 경로인 /var/www/html 디렉토리에 Dockerfile의 copy로 포함할 수 있습니다.

만약 웹 소스 변경사항이 있으면 수정된 웹 소스를 docker cp 명령을 통해서 다시 넣을 수 있습니다. 이때 컨테이너 실행시 볼륨(-v)을 지정하면 docker cp 명령을 사용하지 않고도 해당 볼륨 경로에 변경된 웹소스만 넣어주면 바로 적용이 가능합니다.

94. 바인드 마운트 볼륨 기법을 사용하여 web-volume 디렉토리에 바인드 마운트를 설정합니다.

```java
docker run -d -p 8080:80 \
-v `pwd`/web-volume:/usr/share/nginx/html \
--name=dev-web nginx:1.19
```

![image.png](img/image-354.png)

95. 호스트 운영체제에서 web-volume 디렉토리에 index.html을 작성합니다.

```java
<h1>hello nginx</h1>
```

![image.png](img/image-355.png)

96. nginx 서버에 요청해봅니다.

```java
curl localhost:8080
```

![image.png](img/image-356.png)

97. 호스트 운영체제에서 web-volume 디렉토리 안에 있는 index.html을 다시 수정해봅니다.

```java
vim index.html
```

```java
<h1>Hello, Book shopping web application.</h1>
```

98. 다시 nginx 서버에게 요청해봅니다.

```java
curl localhost:8080
```

![image.png](img/image-357.png)

실행 결과를 보면 컨테이너에 docker cp 명령을 이용하여 /usr/share/nginx/html 디렉토리에 웹 소스를 복사하지 않아도 호스트 운영체제의 바인드 마운트한 디렉토리의 index.html 파일을 수정하면 바로 적용되었습니다.

**실습: 볼륨 용량 제한**

볼륨으로 연결된 컨테이너 내부에서 `df -h` 명령어를 통해서 마운트된 디렉토리(/webapp)의 공간을 조회해보면 호스트 운영체제의 최상위 영역 /(루트 디렉토리)와 /webapp 디렉토리의 용량이 같은것을 알수 있습니다.

이번 실습에서는 바인드 마운트(bind mount) 방식으로 볼륨을 연결하여 조회하고 그 볼륨 사용량을 제한하기 위해서 리눅스에서 사용하는 **dd 명령어**를 통해 임시 영역 512MB를 생성하고 이 임시 영역을 파일 시스템으로 만들어 볼륨 디렉토리로 사용합니다. 이렇게 하면 컨테이너 내부에서 사용할 수 있는 볼륨 공간이 제한됩니다.

99. 바인드 마운트 방식으로 볼륨을 설정하고 그 사용 공간을 비교해봅니다. 우선은 호스트 운영체제에서 사용 공간을 비교해봅니다.

```java
df -h
```

![image.png](img/image-358.png)

실행 결과를 보면 호스트 운영체제에서 루트 디렉토리는 8.7 GB를 사용하고 있습니다.

100. 이번에는 ubuntu 컨테이너를 실행한 다음에 컨테이너 내부에서 사용 공간을 조회해봅니다.

```java
docker run -it -v ~/myvolume:/webapp --name=volume_test ubuntu:14.04 bash
df -h
```

![image.png](img/image-359.png)

실행 결과를 보면 /webapp 디렉토리 또한 호스트 운영체제의 루트 디렉토리와 동일하게 8.9GB를 사용하고 있습니다.

101. ubuntu 컨테이너에서 나온 다음에 dd 명령어를 이용하여 임시 공간을 생성한 다음에 볼륨으로 사용합니다.

```java
sudo dd if=/dev/zero of=temphdd.img count=512 bs=1M
```

- 512MB 크기의 빈 디스크 이미지 파일을 생성합니다.
- dd 명령어는 파일이나 디바이스 간의 데이터를 블록 단위로 복사하는 명령어입니다.
- if=/dev/zero : 입력파일(if, input file)을 지정해야 하는데 /dev/zero를 지정하면 해당 파일은 무한히 0으로 채워진 데이터를 제공합니다.
- of=temphdd.img : 출력파일을 지정합니다.
- count=512 : 512개의 블록 지정
- bs=1M : 한개의 블록 크기를 지정합니다. 여기서는 한개의 블록이 1MB 크기를 차지합니다.

생성된 파일을 확인합니다.

```java
ls -lh temphdd.img
```

![image.png](img/image-360.png)

102. mkfs.ext4 명령어를 이용하여 temphdd.img 파일을 Ext4 파일 시스템으로 포맷합니다.

```java
sudo mkfs.ext4 temphdd.img
```

- mkfs : make file system
- ext4 : Ext4 파일 시스템 유형, extended file system 4

![image.png](img/image-361.png)

103. fdisk 명령어를 이용하여 temphdd.img 파티션을 조회해봅니다.

```java
sudo fdisk -l temphdd.img
```

![image.png](img/image-362.png)

104. 호스트 운영체제에서 webapp 디렉토리를 생성합니다.

```java
mkdir ~/webapp
```

105. temphdd.img 디스크 이미지 파일을 webapp 디렉토리에 마운트합니다.

```java
sudo mount -o loop temphdd.img ~/webapp
```

- mount : 파일 시스템을 특정 디렉토리에 연결하여 사용할 수 있도록 합니다.
    - 위 예제는 temphdd.img를 webapp 디렉토리에 연결하여 디스크처럼 접근이 가능하도록 설정합니다.
- -o loop : 해당 옵션은 마운트 옵션을 지정하는 옵션이고 loop 옵션값은 루프백 디바이스(loopback device)를 사용하여 이미지 파일을 마운트합니다.
    - 일반적으로 mount는 물리적 디스크(/dev/sda1 같은 블록 디바이스)를 마운트하는데 사용됩니다.
    - 그러나 -o loop 옵션을 사용하여 temphdd.img 파일을 가상 디스크처럼 인식하여 마운트가 가능합니다.
    - 즉, 실제 하드웨어 장치 없이 파일을 디스크처럼 사용할때 loop 옵션을 사용합니다.

106. 다시 호스트 운영체제의 사용 공간을 비교합니다.

```java
df -h
```

![image.png](img/image-363.png)

실행 결과를 보면 /dev/loop0 파일 시스템이 /home/ec2-user/webapp 디렉토리에 마운트된것을 볼수 있습니다.

107. webapp 디렉토리의 소유권을 root:root에서 ec2-user:ec2-user로 변경합니다.

```java
sudo chown -R ec2-user.ec2-user ~/webapp
```

![image.png](img/image-364.png)

108. 다시 ubuntu 컨테이너를 실행하여 디스크 사용 공간을 비교해봅니다.

```java
docker run -it -v ~/webapp:/webapp --name=volume_quota ubuntu:14.04 bash
df -h
exit
```

![image.png](img/image-365.png)

실행 결과를 보면 /webapp 디렉토리가 452MB 정도로 마운트 된것을 볼수 있습니다.

109. 실습을 마무리하기 위해서 webapp 디렉토리를 언마운트합니다.

```java
sudo umount ~/webapp
```

## 3.2.4 도커 컨테이너의 자원 사용에 대한 런타임 제약

CPU, 메모리, 디스크 I/O, 네트워크 트래픽 등을 모니터링하기 위해서 다음과 같은 모니터링 툴을 사용합니다.

- top
- htop
- sar
- iostat, df
- vmstat, free
- dstat
- iptraf-ng

컨테이너를 호스트 운영체제에서 실행하는 경우에도 위 도구를 사용해서 자원 사용량을 측정할 수 있습니다. 컨테이너 생성시 별도의 자원 할당 제어를 설정하지 않으면 컨테이너는 호스트 운영체제의 모든 자원을 자유롭게 사용하고 과도하게 자원 사용할 수도 있습니다.

리소스 런타임 제약은 cgroup 기능을 통해서 가능합니다. /proc/mounts 정보나 docker info 명령을 확인할 수 있습니다.

```java
grep cgroup /proc/mounts
```

- 현재 시스템에서 마운트된 cgroup 파일 시스템을 확인합니다.
- /proc/mounts : 현재 마운트된 모든 파일 시스템 목록이 들어있습니다.

![image.png](img/image-366.png)

```java
docker info | grep Cgroup
```

![image.png](img/image-367.png)

cgroup 기능이 비활성화된 경우 docker info 출력 마지막에 경고 표시가 나타나거나 컨테이너 실행시 세부 내용에 대한 경고 표시가 출력됩니다.

위 실행 결과를 보면 별도의 경고 표시가 없기 때문에 Cgroup 기능을 지원합니다.

### 컨테이너 리소스 런타임 제약 옵션

도커에서 제공하는 런타임 제약 옵션 중 대표적인 3가지는 CPU, 메모리, 디스크입니다.

**CPU 리소스 런타임 제약 옵션**

| 도구  | 설명 |
| ----- | ---- |
| —cpus |      |
(0~1, 100%기준) | 컨테이너가 사용 가능한 CPU 리소스 양을 지정.
예시1: —cpus=0.2 ⇒ 1개의 CPU 사용중 이 CPU의 20%만 사용 가능
예시2: —pucs=1.5 ⇒ 여러개의 CPU 사용중인 경우 1.5개의 CPU 사용이 보장 |
| —cpu-period | CPU CFS 기간 제한 옵션으로 컨테이너의 CFS는 100ms로 지정. 일반적으로 이 값은 변경하지 않고 사용. 즉, CPU 스케줄링 주기를 설정합니다. |
| ----------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| —cpu-quota  | CPU 사용량을 제한하는데 사용합니다. —cpu-period와 함께 사용하여 CPU 스케줄링 주기(100ms) 동안 CPU를 얼마나 사용할지 설정합니다.      |
예시: 1개의 CPU 사용시 컨테이너가 100ms마다 런타임의 50%를 CPU에 할당
$ docker run -it \
—cpu-period=100000 \
—cpu-quota=50000 \
ubuntu:14.04 /bin/bash
**일반적으로 —cpus 이용을 권장** |
| —cpuset-cpus | 호스트 운영체제에서 여러개의 CPU 사용시 특정 코어 번호를 지정해서 사용을 제한합니다. CPU 코어는 0부터 시작합니다. |
| ------------ | ----------------------------------------------------------------------------------------------------------------- |
예시1: —cpuset-cpus=”0,3” → 1,4번째 CPU 사용(0번 core, 3번 core 사용)
예시2: —cpuset-cpus=”0-2” → 1,2,3번째 CPU 사용(0,1,2 core 사용) |
| —cpu-shares | **CPU 자원의 상대적인 비율**을 설정 (우선순위, 상대적 CPU 점유율), 기본값 1024 |
| ----------- | ------------------------------------------------------------------------------ |

**실습: —cpu-shares**

110. 현재 사용중인 서버의 CPU 수를 조회합니다. cpuinfo 파일이나 htop 도구를 사용합니다.

```java
grep -c processor /proc/cpuinfo
```

![image.png](img/image-368.png)

실행 결과를 보면 현재 1개의 CPU 코어를 사용하고 있습니다.

111. htop 도구로도 확인해봅니다.

![image.png](img/image-369.png)

112. stress 이미지를 이용하여 CPU 부하를 모니터링해봅니다.

```java
docker run -d --name cpu_1024 \
--cpu-shares 1024 \
leecloudo/stress:1.0 stress --cpu 1
```

```java
docker run -d --name cpu_512 \
--cpu-shares 512 \
leecloudo/stress:1.0 stress --cpu 1
```

113. 2개의 컨테이너 CPU 사용 시간을 측정해봅니다.

```java
ps -auxf | grep stress | grep -v grep
```

![image.png](img/image-370.png)

실행 결과를 보면 첫번째 컨테이너는 29초정도 사용하고 두번째 컨테이너는 11초정도 CPU를 사용하였습니다.

이와 같이 —cpu-shares 옵션을 사용하여 CPU의 사용 비율을 조절할 수 있습니다.

**실습: —cpuset-cpus**

114. CPU 코어 번호 2번, 즉 3번째 CPU를 선택하여 스트레스 컨테이너를 실행합니다.

```java
docker run -d --name cpuset_1 \
--platform "linux/amd64" \
--cpuset-cpus=2 \
leecloudo/stress:1.0 stress --cpu 1
```

![image.png](img/image-371.png)

htop을 통해서 CPU 사용율을 모니터링합니다.

![image.png](img/image-372.png)

115. cpuset_1 컨테이너를 삭제합니다.

```java
docker stop cpuset_1
docker rm cpuset_1
```

**실습: —cpus**

116. 컨테이너의 CPU 사용율을 20%로 제한합니다.

```java
docker run -d --name cpuset_2 \
--platform "linux/amd64" \
--cpuset-cpus=0 \
--cpus=0.2
leecloudo/stress:1.0 stress --cpu 1
```

또는 docker update를 이용하여 CPU 사용율을 변경할 수 있습니다.

```java
docker update --cpus=0.2 cpuset_2
```

**메모리 리소스 런타임 제약 옵션**

| 도구            | 설명                                                                             |
| --------------- | -------------------------------------------------------------------------------- |
| -m 또는 —memory | 컨테이너가 사용할 수 있는 최대 메모리 크기 설정합니다. 허용되는 최솟값은 4m(4mb) |
- b, k, m, g 용량 단위 |
| —memory-swap | 컨테이너가 디스크로 스왑할 수 있는 메모리양을 지정합니다.
0이면 컨테이너의 스왑을 사용하지 않음, -1이면 무제한으로 설정 |
| —kernel-memory | 컨테이너가 사용할 수 있는 최대 커널 메모리양 설정합니다. |

**실습: —memory**

117. ubuntu 컨테이너 실행시 메모리 사용량을 1GB로 제한합니다.

```java
docker run -it -d --name=ubuntu_mem_1g \
--memory=1g \
ubuntu:14.04
```

![image.png](img/image-373.png)

118. ubuntu 컨테이너를 분석하여 memory 부분에서 1GB로 제한되는지 확인합니다.

```java
docker inspect ubuntu_mem_1g | grep -i memory
```

![image.png](img/image-374.png)

실행 결과를 보면 메모리 제한이 1G입니다.

**실습: —memory && —memory-swap**

119. ubuntu 컨테이너의 메모리 사용량을 500MB, 스왑은 1GB로 제한합니다.

```java
docker run -it -d --name=ubuntu_mem_swap \
--memory=500m --memory-swap=1g \
ubuntu:14.04
```

![image.png](img/image-375.png)

120. ubuntu 컨테이너의 메모리와 메모리 스왑 할당량을 확인합니다.

```java
docker inspect ubuntu_mem_swap | grep -i memory
```

![image.png](img/image-376.png)

실행 결과 정상적으로 메모리는 500MB, 메모리 스왑은 1GB로 제한이 설정되어 있습니다.

**실습: —memory 사용시 컨테이너 애플리케이션이 사용하는 메모리양보다 적게 설정되는 경우 오류가 발생합니다. 따라서 사전에 컨테이너 애플리케이션에 적합한 메모리양을 확인한 뒤 설정해야 합니다.**

121. mysql 컨테이너에 메모리 할당 최솟값인 4MB를 할당해봅니다.

```java
docker run -it -d \
--memory=4m \
--name=mysql_mem_4m \
-e MYSQL_ROOT_PASSWORD=root \
mysql:5.7
```

![image.png](img/image-377.png)

실행 결과를 보면 mysql 컨테이너의 최소 메모리 한계량은 6MB입니다. 즉, 메모리 제한할때는 최소 6MB 이상이어야 합니다.

<aside>
💡

예를 들어 100MB로 설정하면 컨테이너가 종료되지는 않지만, mysql 데이터베이스를 동작하기엔 부족할 수 있습니다. 따라서 애플리케이션 운영에 필요한 메모리양을 사전 계산을 하고 할당해야 합니다.

</aside>

**디스크 I/O 리소스 런타임 제약 옵션**

일반적인 디스크 I/O 성능 지표로 MBPS(Mega Byte Per Second, 초당 처리할 수 있는 처리량), IOPS(Input Output Per Second, 초당 I/O 횟수)를 사용하여 전체적인 디스크 블록 I/O를 제한할 수 있습니다.

| 도구                 | 설명                                                        |
| -------------------- | ----------------------------------------------------------- |
| —blkio-weight        | 블록 IO 할당량은 10~1,000 사이의 가중치 값 허용             |
| —blkio-weight-device | 블록 IO 할당량을 제한할 디바이스를 지정함                   |
| —device-read-bps     | 장치의 초당 읽기 속도를 제한함(kb, mb, gb 단위로 설정 가능) |
| —device-write-bps | 장치의 초당 쓰기 속도 제한(kb, mb, gb 단위로 설정 가능) |
| —device-read-iops | 장치의 초당 읽기 I/O 제한(0이상의 정수로 설정해야함) |
| ----------------- | ---------------------------------------------------- |
| —device-write-iops | 장치의 초당 쓰기 I/O 제한(0 이상의 정수로 설정해야함) |

**실습: —device-read-bps & —device-write-bps**

122. ubuntu 컨테이너를 생성합니다.

```java
docker run -it --rm ubuntu:14.04 bash
```

123. dd 명령어를 통해서 임시 디바이스를 생성합니다. 실행 결과로 출력되는 시간과 MBPS 정보를 확인합니다. 호스트의 MBPS 속도를 그대로 사용합니다.

```java
dd if=/dev/zero of=blkio.out bs=1M count=10 oflag=direct
```

- oflag=direct : 직접 입출력 활성화

![image.png](img/image-378.png)

실행 결과를 보면 MBPS는 399MB입니다. 즉, 초당 399MB를 처리할 수 있습니다.

124. 이번에는 컨테이너 생성시 쓰기 MBPS를 10MB로 제한합니다. 10MB로 제한하면 그 아래로 속도로 처리합니다.

```java
docker run -it --rm --device-write-bps /dev/sda:10mb \
ubuntu:14.04 bash
```

125. dd 명령어로 10MB 크기의 임시 디바이스를 생성합니다.

```java
dd if=/dev/zero of=blkio.out bs=1M count=10 oflag=direct
```

## 3.2.5 도커 네트워크
### 도커 네트워크 개요

**실습: 기본 브리지 네트워크 모드**

126. 호스트 운영체제에 기본으로 설치된 docker0의 IP 주소를 확인합니다.

```java
ifconfig docker0
```

![image.png](img/image-379.png)

- docker0은 Docker 브리지 네트워크 인터페이스. Docker 컨테이너들이 내부적으로 통신할때 사용하는 가상 네트워크 장치입니다.
- flags=4099<UP, BROADCAST, MULTICAST>
    - Up : 네트워크 인터페이스가 활성화됨
    - BROADCAST : 브로드캐스트 패킷을 지원함
    - MULTICAST : 멀티캐스트 패킷을 지원함
- inet 172.17.0.1 network 255.255.0.0 broadcast 172.17.255.255
    - IPv4 주소 : 172.17.0.1 (Docker 네트워크의 기본 게이트웨이 역할)
    - 서브넷 마스크 : 255.255.0.0 (클래스 B, 65,536개의 IP 주소를 가질 수 있음)
    - 브로드캐스트 주소 : 172.17.255.255 (이 네트워크의 모든 장치로 패킷을 보낼수 있음)
        - 브로드캐스트 주소는 특정 네트워크에 속하는 모든 호스트들이 갖게되는 주소입니다. 네트워크에 있는 모든 클라이언트들에게 데이터를 전송하기 위해서 사용합니다.
- inet6 fe80::42:c1ff:fe0c:e616  prefixlen 64  scopeid 0x20<link>
    - IPv6 주소 : fe80::42:c1ff:fe0c:e616 (Link-Local 주소)
    - IPv6에서는 네트워크 인터페이스 간 자동 통신을 위한 로컬 주소가 할당됩니다.
- ether 02:42:c1:0c:e6:16
    - MAC 주소(이더넷 주소) : 02:42:c1:0c:e6:16
    - Docker가 가상 네트워크 인터페이스를 생성할때 자동으로 할당되는 MAC 주소
- RX (Received, 수신 패킷)
    - RX packets 22435 : 22435개의 패킷을 수신함
    - bytes 532744371 (508.0 MiB) : 총 508.0 MB 데이터 수신
    - RX errors 0 : 수신 에러 없음
    - dropped 0 : 버린 패킷 없음
- TX (Transmitted, 송신 패킷)
    - TX packets 16735 : 16735개의 패킷을 송신함
    - bytes 1318076 (1.2 MiB) : 총 1.2MB 데이터 송신
    - TX errors 0 : 송신 에러 없음
    - dropped 0 : 버린 패킷 없음

127. 현재 설정되어 있는 도커 네트워크 드라이버 방식을 조회합니다.

```java
docker network ls
```

![image.png](img/image-380.png)

- bridge는 Docker가 기본적을 제공하는 **Bridge 네트워크**입니다.
    - 컨테이너들이 같은 네트워크에서 통신하도록 합니다.
- host 드라이버 방식은 컨테이너가 호스트의 네트워크 인터페이스를 직접 사용하는 방식입니다.
    - 컨테이너 내부에서 localhost로 접근하면 실제 호스트의 네트워크를 이용
    - Docker가 따로 IP주소를 할당하지 않음
- none 드라이버 방식은 네트워크 인터페이스를 비활성화한 네트워크
    - 컨테이너가 어떠한 네트워크에도 자동으로 연결되지 않음
    - 완전히 독립적인 환경으로 구성됨
    - 인터넷 접근 및 다른 컨테이너와의 통신이 불가능합니다.

128. ubuntu 컨테이너 2개를 실행합니다.

```java
docker run -it -d --name container1 ubuntu:14.04
docker run -it -d --name container2 ubuntu:14.04
```

![image.png](img/image-381.png)

129. docker inspect 명령어를 통해서 container1, container2의 IP, Max를 조회합니다.

```java
docker inspect container1 | grep IPAddress
```

![image.png](img/image-382.png)

실행 결과를 보면 container1의 IPv4 주소는 172.17.0.2입니다.

```java
docker inspect container2 | grep IPAddress
```

![image.png](img/image-383.png)

실행 결과를 보면 container2의 IPv4 주소는 172.17.0.3입니다.

130. container1의 ip 설정을 조회합니다.

```java
docker exec container1 ifconfig
```

![image.png](img/image-384.png)

- eht0 inet addr:172.17.0.2 : container1의 IPv4 주소

131. container1의 라우트 정보를 조회합니다.

```java
docker exec container1 route
```

![image.png](img/image-385.png)

**default 목적지**

- Destination : default는 모든 외부 트래픽의 기본 경로
- Gateway : 172.17.0.1 → 패킷이 docker0 브리지 네트워크(호스트의 게이트웨이)로 전달됨
- Genmask : 0.0.0.0 → 서브넷 마스크가 전부 0이므로 모든 트래픽이 이 경로를 사용 가능
- Flags : UG
    - U : 이 경로가 활성 상태
    - G : 게이트웨이를 통해 경로가 설정됨
- Iface : eth0 → 이 트래픽은 컨테이너의 eth0 인터페이스를 통해 전송됨

컨테이너에서 인터넷으로 나가거나 인터넷에서 컨테이너로 들어오는 모든 트래픽은 172.17.0.1(Docker 브리지 네트워크의 게이트웨이)를 거쳐서 나갑니다.

**172.17.0.0 목적지**

- Destination : 172.17.0.0 → 172.17.0.0/16 서브넷에 속한 모든 IP주소로 가는 경로
- Gateway : * → 게이트웨이 없음, 즉, 직접 통신이 가능합니다.
- Genmask : 255.255.0.0 → 172.17.0.0/16 서브넷
- Flags : U
    - U → 경로 활성화 상태
- Iface : eth0 → 컨테이너 내부의 네트워크 인터페이스 eth0 사용

컨테이너 내부에서 172.17.0.0/16 대역의 IP(같은 docker 브리지 네트워크 내의 다른 컨테이너들)로 직접 통신이 가능함

132. 호스트 운영체제에서 IP 정보를 조회합니다.

```java
ifconfig
```

![image.png](img/image-386.png)

컨테이너 개수만큼의 가상 네트워크 인터페이스 vthxxxx가 자동 추가됩니다. 이 인터페이스는 별도의 IP 주소가 할당되지 않은 터널링 서비스만 제공됩니다.

133. 도커에서 제공하는 네이티브 네트워크 드라이버를 조회합니다.

```java
docker info | grep Network
```

![image.png](img/image-387.png)

- bridge : 기본 네트워크 드라이버, 컨테이너 실행할 때 별도 네트워크 지정이 없으면 bridge 네트워크 드라이버로 설정됩니다.
- host : 컨테이너가 호스트의 네트워킹을 그대로 사용하는 방식입니다.
- overlay : 다중 호스트 도커 서버를 이용한 클러스터(도커 스웜) 등을 이용하는 경우 호스트와 호스트 간의 컨테이너 연결할수 있습니다.
- macvlan : 컨테이너와 mac 주소를 가진 물리적 네트워크를 연결하여 통신하는 방식입니다. 도커 데모은 mac 주소별로 트래픽을 라우팅합니다.
- none : 컨테이너가 네트워크를 사용하지 않습니다. lo 인터페이스만 존재합니다.
- 컨테이너 네트워크: container:공유받을 컨테이너 이름 옵션은 컨테이너의 네트워크 네임스페이스 스택을 (IP주소, Mac 주소 등)을 공유하여 같이 사용합니다.
- 사용자 정의 네트워크 : docker network create 명령어를 통해서 생성한 네트워크를 연결합니다.

**정리**

**네 가지 인터페이스**

- **enp0s8**
    - Ubuntu 리눅스 네트워크 카드
- **docker0**
    - 도커 설치시 기본 제고오디는 브리지 네트워크, 172.17.0.1 주소를 갖습니다.
    - DHCP로 연결된 컨테이너에 사전 정의된 IP를 할당합니다.
- **vethxxxx**
    - OSI 7 계층 모델 중 2계층 서비스(데이터 링크 계층)
    - 컨테이너 내부에 제공되는 네트워크 인터페이스인 eth0와 한쌍으로 제공함
    - docker0와 가상의 터널링 네트워크 제공
- **eth0**
    - 도커 컨테이너에 생성되는 기본 네트워크 인터페이스명. docker0를 게이트웨이로 사용합니다.

![image.png](img/image-388.png)

**실습: 호스트 모드**

134. nginx 이미지에 노출된 포트 80번을 호스트 포트 80번에 연결해서 호스트 IP를 이용해서 서비스합니다.

```java
docker run -d --name=nginx_host \
--net=host \
nginx
```

135. 호스트 운영체제에서 80번 포트의 네트워크 상태를 조회합니다.

```java
sudo netstat -nlp | grep 80
```

- netstat : 네트워크 연결 상태 표시하는 명령어
- -n : 도메인 네임이 아닌 IP, 포트번호로 표시
- -l : LISTEN 상태의 소켓만 출력
- -p : 해당 포트를 사용하는 프로세스 정보 출력(프로세스 이름 및 PID 표시)

![image.png](img/image-389.png)

- 1303188/nginx:mast
    - 1303188 : PID
    - nginx:mast : 실행중인 프로세스, mast는 master의 일부명

136. 호스트 운영체제에서 80번 포트로 요청을 날립니다.

```java
curl localhost:80
```

![image.png](img/image-390.png)

실행 결과를 보면 컨테이너 내부에서 실행하는 것도 아닌 호스트 운영체제에서 요청을 날려도 서버에서 응답합니다.

137. 호스트 운영체제에서 nginx 프로세스의 프로세스 상태를 출력합니다.

```java
ps -ef | grep 1303188
```

![image.png](img/image-391.png)

실행 결과를 보면 호스트 운영체제에서 직접 PID를 할당받아 서비스하고 있습니다.

138. nginx 컨테이너의 IP를 조회해봅니다.

```java
docker inspect nginx_host | grep IPAddress
```

![image.png](img/image-392.png)

실행 결과를 보면 컨테이너의 별도의 IPv4 주소가 할당되어 있지 않습니다. 이는 컨테이너의 네트워크가 브리지 모드가 호스트 모드이기 때문에 별도 할당할 필요가 없기 때문입니다.

### 도커 기본 브리지 네트워크 활용
도커의 기본 네트워크 구성은 브리지 모드를 사용합니다. 도커 데몬을 통해서 도커 컨테이너들의 네트워크를 실제 서버 네트워크와 분리해서 독립적으로 구성합니다.

#### **실습: 브리지 모드**
##### 1. nginx 컨테이너를 실행합니다.
```shell
docker run -d --name=nginx-net -p 8080:80 nginx:1.19
```
![[img/image-393.png]]

##### 2. 호스트 운영체제의 IP 정보를 조회합니다.
```
ifconfig
```
![[img/image-394.png]]
![[img/image-395.png]]

##### 3. nginx 서비스 접속
호스트 운영체제의 curl을 이용해서 nginx 서버에 요청을 날려봅니다.
```shell
curl localhost:8080
```
![[img/image-396.png]]

##### 4. 8080 포트 네트워크 상태 확인
```shell
sudo netstat -nlp | grep 8080
```
![[img/image-397.png]]
실행 결과를 보면 8080 포트는 docker 프로세스가 사용하고 있습니다.

##### 5. 프로세스 상태 확인
PID 1305508 프로세스의 상태를 조회합니다.
```shell
ps -ef | grep 1305508 | grep -v grep
```
![[img/image-398.png]]
실행 결과를 보면 TCP 프로토콜 방식으로 호스트 포트 8080번 포트가 도커 container 80번 포트로 매핑되어 있습니다.


#### Nginx 웹 서비스 접근 수행 과정
139. 웹 브라우저에서 `http://3.35.207.14:8080` 입력하고 접속합니다.
140. 호스트 운영체제에 8080 포트가 열려있음을 확인하고 해당 포트에 연결된 컨테이너를 찾습니다.
141. 입력한 외부 IP(3.35.207.14)와 포트번호(8080)가 컨테이너와 연결된 브리지 네트워크의 Private IP(172.17.0.2)와 포트번호(80)로 변환됩니다.
	- 즉, 3.35.207.14:8080 -> 172.17.0.2:80 으로 변환됨
142. 3단계에서 발생한 서비스가 **네트워크 주소 포트 변환(NAPT, Network Address Port Translation)** 입니다. 
	- **NAT(Network Address Translation)** 는 발신자의 사설망에서 외부망 IP를 변환해주는 역할만 수행하지만, NAPT는 포트까지 변경해줍니다.


#### 실습: docker 커스텀 네트워크 생성

##### 1. 도커 커스텀 네트워크 생성
```shell
docker network create webapp-vnet
```

위와 같이 네트워크를 생성할 수도 있고 아니면 다음과 같이 `--driver` 옵션을 추가하여 명세적으로 브리지 모드를 추가할 수 있습니다. 옵션 생략시 브리지 모드로 설정됩니다.
```shell
docker network create --driver=bridge webapp-vnet
```

```shell
docker network create mobileapp-vnet
```

##### 2. 도커 네트워크 목록 조회
위 단계에서 생성한 도커 커스텀 네트워크를 확인합니다.
```shell
docker network ls
```
![[img/image-399.png]]

##### 3. 브릿지 조회

```shell
ip link show type bridge
```
![[img/image-400.png]]
실행 결과를 보면 webapp-vnet의 브릿지 ID인 ca4b17d45c38와 mobileapp-vnet의 브릿지 ID인 f62bce505b71가 존재합니다. 그리고 기본적인 docker0 브릿지 네트워크도 존재합니다.

##### 4. 브릿지 네트워크 IPv4 조회
호스트 운영체제에서 webapp-vnet과 mobileapp-vnet 브릿지 네트워크의 IPv4를 확인합니다.
```shell
ifconfig
```
![[img/image-401.png]]
- webapp-vnet(br-ca4b17d45c38) IPv4 : 172.26.0.1
- mobileapp-vnet(br-f62bce505b71) IPv4 : 172.27.0.1

##### 4. 컨테이너 생성시 네트워크 설정
ubuntu 컨테이너를 생성할때 위 단계에서 생성한 webapp-vnet 네트워크와 mobileapp-vnet 네트워크를 설정합니다.
```shell
docker run -it -d --name=webapp --net=webapp-vnet ubuntu:14.04
docker run -it -d --name=mobileapp --net=mobileapp-vnet ubuntu:14.04
```
![[img/image-402.png]]

##### 5. 컨테이너의 할당된 IPv4 주소 확인
실행중인 ubuntu 컨테이너들의 할당받은 IPv4 주소를 확인합니다.
```shell
docker inspect webapp | grep IPAddress
docker inspect mobileapp | grep IPAddress
```
![[img/image-403.png]]
실행 결과를 보면 webapp 컨테이너는 172.26.0.2 주소를 할당받고, mobileapp 컨테이너는 172.27.0.2 주소를 할당받았습니다.

##### 6. 도커 네트워크 정보 분석
webapp-vnet 네트워크 정보를 조회합니다.
```shell
docker network inspect webapp-vnet
```
![[img/image-404.png]]
![[img/image-405.png]]
- 게이트웨이 주소가 172.26.0.1 입니다.
- 해당 네트워크에 속한 컨테이너는 webapp이 속해있습니다. 그리고 그 컨테이너는 172.26.0.2 주소를 할당받았습니다.

#### 실습: 특정 네트워크 IP 대역을 설정하여 도커 네트워크 생성
브릿지 네트워크 IP 대역은 별도 명시가 없으면 순차적으로 할당됩니다. 하지만 특정 대역을 설정하여 도커 네트워크를 생성 할 수 있습니다.

##### 1. 도커 네트워크 생성
```shell
docker network create \
--driver bridge \
--subnet 172.100.1.0/24 \
--ip-range 172.100.1.0/24 \
--gateway 172.100.1.1 \
custom-net
```
- 위 네트워크 생성시 해당 네트워크에 속한 컨테이너들은 172.100.1.0 ~ 172.100.1.255 사이의 IP 주소를 할당받습니다. 여기서 172.100.1.1은 게이트웨이 주소로 미리 할당됩니다.

![[img/image-406.png]]

##### 2. 도커 네트워크 정보 분석
```shell
docker network inspect custom-net
```
![[img/image-407.png]]
![[img/image-408.png]]

##### 3. 컨테이너 실행시 네트워크 설정
ubuntu 컨테이너 실행시 위 단계에서 생성한 네트워크 custom-net 네트워크를 설정합니다.
```shell
docker run -it -d \
--name=cust-net1 \
--net=custom-net \
ubuntu:14.04

docker run -it -d \
--name=cust-net2 \
--net=custom-net \
--ip 172.100.1.100 \
ubuntu:14.04
```
cust-net2 컨테이너의 IPv4 주소를 자동할당되지 않고 특정 IP를 명세합니다.

##### 4. 컨테이너의 할당된 IPv4 주소 확인
```shell
docker network inspect custom-net | grep IPv4Address
```
![[img/image-409.png]]
실행 결과 cust-net1, cust-net2 컨테이너의 IPv4 주소가 각각 172.100.1.2, 172.100.1.100 할당되었습니다.

##### 5. 라우팅 네트워크 확인
```shell
route
```
![[img/image-410.png]]
실행 결과를 보면 custom-net(br-a53bb7340af8)의 라우팅 정보가 조회되었습니다.

##### 6. 컨테이너에서 다른 컨테이너로 ping 요청
cust-net1 컨테이너에서 ping 명령어로 cust-net2 컨테이너로 ping 명령어를 날려봅니다. 만약 네트워크가 잘 설정되었다면 ping/pong이 될것입니다.
```shell
docker exec -it cust-net1 bash
ping -c 3 cust-net2
```
![[img/image-411.png]]
실행 결과를 보면 정상적으로 ping/pong이 됩니다.

#### 실습: 도커 컨테이너에 새로운 네트워크 추가
##### 1. app-net 이름의 브릿지 모드의 도커 네트워크 생성
```shell
docker network create --driver=bridge app-net
```
![[img/image-412.png]]

##### 2. 컨테이너 생성 및네트워크 설정
ubuntu 컨테이너를 생성하면서 app-net 네트워크를 설정합니다.
```shell
docker run -it -d --name=ubuntu-container --net=app-net ubuntu:14.04
docker exec -it ubuntu-container bash
```
![[img/image-413.png]]
실행 결과를 보면 컨테이너의 IPv4 주소 172.28.0.2가 app-net의 주소인 172.28.0.0/16에 속하는 것을 알수 있습니다.

##### 3. 관리용 네트워크 생성
```shell
docker network create --driver=bridge admin-net
```
![[img/image-414.png]]
![[img/image-415.png]]
생성된 admin-net CIDR가 172.29.0.0/16 인것을 알수 있습니다.

##### 4. 관리용 네트워크와 컨테이너 연결 추가
실행중인 ubuntu 컨테이너에 관리용 네트워크인 admin-net을 추가합니다.
```shell
docker network connect admin-net ubuntu-container
```

##### 5. 컨테이너의 라우트 정보 확인
```
docker exec ubuntu-container route
```
![[img/image-416.png]]
위 실행 결과에서 172.29.0.0이 admin-net 브릿지 네트워크 인터페이스입니다. 즉, 성공적으로 app-net과 admin-net 모두와 연결이 된 상태입니다.

##### 6. 컨테이너 내부에서 설정된 네트워크 정보 확인
```
docker exec ubuntu-container ifconfig
```
![[img/image-417.png]]
실행 결과를 보면 app-net 네트워크에서 할당된 ubuntu-container의 IPv4 주소(eth0)는 172.28.0.2로 할당되었습니다. 그리고 admin-net 네트워크에서 할당된 ubuntu-container의 IPv4 주소(eth1)는 172.29.0.2로 할당되었습니다.


##### 6. 네트워크에 할당된 컨테이너 조회
admin-net 네트워크에 할당된 컨테이너를 확인합니다.
```shell
docker network inspect admin-net
```
![[img/image-418.png]]
실행 결과를 보면 admin-net 네트워크에 836c 컨테이너가 할당되었고 해당 컨테이너는 172.29.0.2 IPv4 주소가 할당되었습니다.

##### 7. 도커 네트워크 삭제
admin-net 네트워크를 삭제해봅니다.
```shell
docker network rm admin-net
```
![[img/image-419.png]]
admin-net 네트워크를 삭제하고자 했으나 연결된 컨테이너가 존재하기 때문에 삭제할 수 없습니다.

##### 8. 네트워크와 연결된 컨테이너 연결해제
ubuntu-container 컨테이너를 대상으로 admin-net 네트워크를 연결해제합니다.
```shell
docker network disconnect admin-net ubuntu-container
```

##### 9. 도커 네트워크 삭제 재시도
```shell
docker network rm admin-net
```
![[img/image-420.png]]

#### 실습: 컨테이너의 네트워크 네임스페이스 스택 공유
네트워크 네임스페이스 스택 공유 기능을 이용하여 하나의 vethxxxx와 IP 주소, Mac 주소를 공유합니다.

##### 1. httpd 컨테이너 생성
바인드 마운트 방식으로 볼륨을 설정하고 그 사용 공간을 비교해봅니다.
```shell
docker run -d --name=httpd-server httpd
```

```shell
docker run -d --name=redis-server --net=container:httpd-server redis
```

```shell
docker ps
```
![[img/image-421.png]]

##### 2. 컨테이너 IPv4 할당 확인
```shell
docker inspect httpd-server | grep IPAddress
docker inspect redis-server | grep IPAddress
```
![[img/image-422.png]]
실행 결과를 보면 httpd-server는 172.17.0.2 주소로 할당된 반면에 redis-server는 IPv4 주소가 할당되지 않았습니다. 

httpd 컨테이너는 외부와 통신이 가능하고 redis 컨테이너는 내부 네트워크 컨테이너로써 httpd-server 컨테이너와만 통신이 가능합니다.

### 도커 사용자 정의 네트워크 활용
#### --net alias와 도커 DNS 서비스를 활용한 부하 분산
컨테이너 실행시 `--net-alias` 또는 --link 옵션을 사용한 컨테이너에는 기본적으로 서비스를 검색할 수 있는 **내장 DNS 서버**가 제공됩니다. 이러한 내장 DNS 서버를 자동화 DNS 확인(automatic DNS resolution)이라고 합니다.

예를 들어 프론트엔드의 talkapp이 있고 백엔드에 mydb라는 컨테이너가 있습니다. 두 컨테이너는 통신시 IP 주소가 아닌 컨테이너 이름만으로도 통신이 가능합니다. 왜냐하면 내장 DNS 서버가 존재하기 때문에 특정 네트워크에서 모든 컨테이너의 별칭과 해당 IP 주소가 매핑을 유지하기 때문입니다.

이 내장 DNS 서버는 컨테이너의 IP가 변경되거나 신규 컨테이너가 포함되면 자동 감지를 통해서 해당 컨테이너의 IP를 등록하고 반환합니다.

#### 실습: 내장 DNS 서버 활용
##### 1. 사용자 정의 네트워크 생성
사용자 정의 네트워크인 netlb 네트워크를 생성합니다.
```shell
docker network create \
--driver bridge \
--subnet 172.200.1.0/24 \
--ip-range 172.200.1.0/24 \
--gateway 172.200.1.1 \
netlb
```
![[img/image-423.png]]
![[img/image-424.png]]

##### 2. --net-alias 옵션을 사용하여 컨테이너 생성
ubuntu 컨테이너 3개를 생성하고 netlb 네트워크를 설정합니다. 그리고 각 컨테이너의 net-alias를 inner-dns-net으로 설정합니다.
```shell
docker run -it -d --name=nettest1 \
--net=netlb \
--net-alias inner-dns-net \
ubuntu:14.04
```
```shell
docker run -it -d --name=nettest2 \
--net=netlb \
--net-alias inner-dns-net \
ubuntu:14.04
```
```shell
docker run -it -d --name=nettest3 \
--net=netlb \
--net-alias inner-dns-net \
ubuntu:14.04
```

##### 3. 컨테이너의 IPv4 주소 확인
```shell
docker inspect nettest1 | grep IPAddress
docker inspect nettest2 | grep IPAddress
docker inspect nettest3 | grep IPAddress
```
![[img/image-425.png]]

##### 4. 동일 사용자 정의 네트워크에 연결된 프론트엔드 컨테이너 생성
```shell
docker run -it --rm --name=frontend --net=netlb ubuntu:14.04 bash
```

##### 5. frontend 컨테이너에서 ping 명령어 수행
```shell
ping -c 2 inner-dns-net
```

![[img/image-426.png]]
실행 결과를 보면 nettest2(172.200.1.3)이 핑퐁하고, 다시한번 수행시 nettest1(172.200.1.2)이 핑퐁하였습니다. 즉, 컨테이너 내부에서 별칭에 포함된 네트워크에 ping을 시도합니다. 무작위로 선택된 컨테이너가 ping을 받아주는 것을 확인할 수 있습니다.

##### 6. DNS 정보 확인
위 단계에서 수행한 frontend 컨테이너 배시쉘에서 수행합니다.
```shell
apt-get update
apt-get -y install dnsutils
dig inner-dns-net
```
![[img/image-427.png]]
실행 결과를 보면 inner-dns-net DNS에 3개의 IP 주소가 등록되어 있습니다.

##### 7. 새로운 컨테이너를 추가하여 별칭에 포함
```shell
docker run -it -d --name=nettest4 \
--net=netlb \
--net-alias inner-dns-net \
ubuntu:14.04
```

다시 frontend 쉘로 접속하여 dns 정보를 확인해봅니다.
```shell
dig inner-dns-net
```

![[img/image-428.png]]
위 실행 결과를 보면 새로운 컨테이너에 대한 IPv4 주소가 내부 DNS서버에 추가된 것을 확인할 수 있습니다. 이는 내부 DNS 서버가 컨테이너가 새로 추가되는 경우에 자동 추가되는 것을 볼수 있습니다.

**정리**
사용자 정의 브리지 네트워크의 DNS 서비스 기능을 사용하면 네트워크 별칭(--net-alias)을 통해 부하를 분산시킬수 있는 **로드 밸런스**로 활용할 수 있습니다.

도커 도큐먼트에서는 기본 브리지보다는 사용자 정의 브리지 네트워크를 권장하고 있습니다. 연결과 해제가 자유롭기 때문입니다.

기본 브리지 네트워크는 docker0 인터페이스를 사용합니다. `--link` 옵션없이도 IP 주소로 통신 가능하지만, 컨테이너 이름으로 통신할 수는 없습니다. 반면에 docker network create 명령어로 생성한 사용자 정의 브릿지 네트워크는 컨테이너 이름으로 통신할 수 있습니다. 또한 `--net-alias` 옵션을 이용하면 해당 옵션으로 지정한 그룹으로 부하를 분산하는 로드밸런서 역할을 수행할 수 있습니다.

#### nginx를 이용한 컨테이너 로드 밸런서 구축
로드 밸런서를 이용하면 많은 클라이언트의 요청을 동일 웹 서버 등에 분산시켜서 처리할수 있습니다. 이러한 로드 밸런서는 도커에서는 HaProxy, Nginx/Apache Load Balancer 등 외부 서비스와 컨테이너를 결합하여 로드 밸런서 구축이 가능합니다.

#### 실습: nginx 컨테이너를 이용한 로드 밸런서 구축
nginx를 호스트 운영체제에 설치하고 nginx를 프록시 역할로 구성을 변경하고 nginx로 들어오는 패킷을 연결된 컨테이너에 업스트림(upstream) 합니다.

##### 1. 호스트 운영체제에 nginx 설치
```shell
sudo yum update
sudo yum -y install nginx
sudo systemctl start nginx
sudo systemctl status nginx.service
```
![[img/image-429.png]]

nginx가 오프한 80번 포트를 확인합니다.
```shell
sudo netstat -nlp | grep 80
```
![[img/image-430.png]]

##### 2. phpserver 다운로드
```shell
git clone https://github.com/brayanlee/docker-phpserver.git
cd docker-phpserver/
ls
```
![[img/image-431.png]]

##### 3. 도커 이미지 빌드
phpserver:1.0 이미지 이름으로 이미지를 빌드합니다.
```shell
docker build -t phpserver:1.0 .
docker images
```
![[img/image-432.png]]

##### 4. nginx 프록시와 연결된 php 컨테이너 생성
phpserver:1.0 이미지를 기반으로 컨테이너 3개를 생성합니다.

```shell
docker run -it -d -p 5001:80 \
-h nginx-lb01 \
-v `pwd`/lb01:/var/log/apache2 \
-e SERVER_PORT=5001 \
--name=nginx-lb01 \
phpserver:1.0
```
```shell
docker run -it -d -p 5002:80 \
-h nginx-lb02 \
-v `pwd`/lb02:/var/log/apache2 \
-e SERVER_PORT=5002 \
--name=nginx-lb02 \
phpserver:1.0
```
```shell
docker run -it -d -p 5003:80 \
-h nginx-lb03 \
-v `pwd`/lb03:/var/log/apache2 \
-e SERVER_PORT=5003 \
--name=nginx-lb03 \
phpserver:1.0
```

![[img/image-433.png]]

##### 5. php 파일을 컨테이너에 복사
기본 페이지로 사용할 index.php3 파일을 컨테이너에 각각 복사합니다.

```shell
docker cp index.php3 nginx-lb01:/var/www/html/index.php
docker cp index.php3 nginx-lb02:/var/www/html/index.php
docker cp index.php3 nginx-lb03:/var/www/html/index.php
```
![[img/image-434.png]]

##### 6. 컨테이너와 연결된 포트 확인
```shell
sudo netstat -nlp | grep 5001
sudo netstat -nlp | grep 5002
sudo netstat -nlp | grep 5003
```
![[img/image-435.png]]

##### 7. nginx 프록시 구성
기본 listen되는 80번 포트를 통해 패킷이 들어오면 proxy_pass를 이용하여 http://nginx-lb 도메인명의 upstream으로 이동합니다. 각 포트별로 라운트 로빈 방식으로 컨테이너에 패킷을 전달합니다.
```shell
cd /etc/nginx/
sudo vim nginx.conf
```
```
# For more information on configuration, see:

#   * Official English Documentation: http://nginx.org/en/docs/

#   * Official Russian Documentation: http://nginx.org/ru/docs/

  

user nginx;

worker_processes auto;

error_log /var/log/nginx/error.log notice;

pid /run/nginx.pid;

  

# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.

include /usr/share/nginx/modules/*.conf;

  

events {

    worker_connections 1024;

}

  

http {

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '

                      '$status $body_bytes_sent "$http_referer" '

                      '"$http_user_agent" "$http_x_forwarded_for"';

  

    access_log  /var/log/nginx/access.log  main;

  

    sendfile            on;

    tcp_nopush          on;

    keepalive_timeout   65;

    types_hash_max_size 4096;

  

    include             /etc/nginx/mime.types;

    default_type        application/octet-stream;

  

    # Load modular configuration files from the /etc/nginx/conf.d directory.

    # See http://nginx.org/en/docs/ngx_core_module.html#include

    # for more information.

    include /etc/nginx/conf.d/*.conf;

    upstream backend-lb{
	    server 127.0.0.1:5001;
		server 127.0.0.1:5002;
		server 127.0.0.1:5003;
    }

    server {
        listen       80 default_server;
        listen       [::]:80 default_server;
        
		location / {
			proxy_pass http://backend-lb;
		}
    }
}
```

nginx 서비스를 재시작하고 상태확인합니다.
```shell
sudo systemctl restart nginx.service
sudo systemctl status nginx.service
```
![[img/image-436.png]]

##### 8. localhost에 요청 날려보기
```shell
curl localhost
```
![[img/image-437.png]]
실행 결과를 보면 localhost에 요청을 날릴때마다 서로 다른 php 서버가 처리하는 것을 볼수 있습니다. 이는 로드밸런서를 정상적으로 구축함을 의미합니다.

##### 9. php 서버의 로그 확인
```shell
cat lb01/access.log
cat lb02/access.log
cat lb03/acess.log
```
![[img/image-438.png]]
실행 결과를 보면 사용자가 접근한 기록이 로그로 남겨있습니다. 현재 적용된 로드 밸런서 알고리즘은 차례대로 순환하는 라운드 로빈 방식입니다.

**nginx 로드 밸런서 연결 알고리즘**
다음 설명에서 나오는 경로 보장이 안되는다는 의미는 클라이언트 요청이 항상 동일한 백엔드 서버로 전달되지 않는다는 것을 의미합니다.

| 연결 알고리즘                  | 설명                                                                                                                                                                                          |
| ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 라운드 로빈(Round-Robin, RR)  | 요청을 서버 가중치를 고려하여 균등 배포하는 방식, 경로 보장 안됨, (기본값)                                                                                                                                                |
| 최소 연결(Least Connections) | 현재 연결된 클라이언트 수가 가장 적은 서버로 요청 전달, 경로 보장 안됨                                                                                                                                                   |
| IP 해시(IP hash)           | 해시 키를 이용하여 IP별 INDEX를 생성하여 동일한 IP주소는 동일한 서버로의 경로를 보장합니다.  해당 서버가 장애가 발생하면 변경됩니다. 균등 배포 보장하지 않습니다.                                                                                           |
| 일반 해시(general hash)      | 사용자가 정의하는 키(IP, Port, URI 문자열 등)를 이용한 서버 지정 방식                                                                                                                                              |
| 최소 시간(Least Time)        | 낮은 평균 지연시간을 다음 지시자를 기준으로 계산하여 서버를 지정합니다. 즉, 가장 빠른 서버를 선택합니다.<br>- header: 서버의 첫번째 바이트를 받는 시간 기준<br>- last_byte : 서버에서 전체 응답을 받는 시간 기준<br>- last_byte_inflight : 불완전 요청을 고려한 전체 응답을 받는 시간 기준 |
| 무작위(random)              | 무작위 서버를 선택합니다.                                                                                                                                                                              |

**nginx 로드 밸런서 파라미터**
연결 알고리즘을 선택하고 서버 주소 옆에 몇가지 파라미터 설정을 통해서 분배 정책을 세분화할 수 있습니다. 동시선택도 가능합니다.

| 연결 알고리즘         | 설명                                                      |
| --------------- | ------------------------------------------------------- |
| weight          | 가중치(weight) 설정하고 서버간 요청 분배(기본값=1)                       |
| max_cons, queue | 최대 클라이언트 연결 개수 지정과 대기열을 생성합니다.                          |
| max_fails       | 최대 실패 횟수를 설정해서 임계치 도달하면 해당 서버를 분배 대상에서 제외합니다.          |
| fail_timeout    | 응답의 최소 시간을 설정해서 실패횟수를 카운팅합니다. 보통 max_fails와 함께 사용합니다.   |
| backup          | backup 키워드가 있는 서버는 평소에는 동작하지 않고, 모든 서버가 동작하지 않을때 사용합니다. |
| down            | down 키워드가 있는 서버는 사용하지 않음. ip_hash인 경우만 사용합니다.           |

#### 실습: nginx 로드밸런서 알고리즘 및 파라미터 적용
##### 1. 컨테이너 실행
```shell
docker run -it -d -p 5001:80 \
-h nginx-lb01 \
-v `pwd`/lb01:/var/log/apache2 \
-e SERVER_PORT=5001 \
--name=nginx-lb01 \
phpserver:1.0
```
```shell
docker run -it -d -p 5002:80 \
-h nginx-lb02 \
-v `pwd`/lb02:/var/log/apache2 \
-e SERVER_PORT=5002 \
--name=nginx-lb02 \
phpserver:1.0
```
```shell
docker run -it -d -p 5003:80 \
-h nginx-lb03 \
-v `pwd`/lb03:/var/log/apache2 \
-e SERVER_PORT=5003 \
--name=nginx-lb03 \
phpserver:1.0
```

##### 2. nginx 설정 파일 수정
nginx 설정 파일을 수정해서 weight 파라미터를 각각의 서버거 URL에 설정합니다.
```shell
sudo vim /etc/nginx/nginx.conf
```
```text
http{
	# ...
	upstream backend-lb{
        server 127.0.0.1:5001 weight=6;
        server 127.0.0.1:5002 weight=2;
        server 127.0.0.1:5003 weight=2;
    }
}
```
위와 같이 각각의 서버에 가중치(weight)를 설정하면 10번의 요청이 오면 6개는 5001 포트로, 2개는 5002 포르토, 나머지 2개는 5003 포트로 분배될 것입니다.

nginx 서비스를 재시작합니다.
```shell
sudo systemctl restart nginx.service
sudo systemctl status nginx.service
```

##### 3. php 서버로 요청해보기
php 서버에 요청해서 가중치대로 분배하는지 확인하기 위해서 다음과 같이 명령어를 실행합니다. watch 명령어를 이용해서 1초 간격으로 localhost를 요청합니다. 
```shell
watch -n 1 curl localhost
```

실행 결과를 보면서 5001포트로 몇번 가는지 확인합니다.
![[img/image-439.png]]

#### 실습: 최소 연결 알고리즘
```text
http{
	# ...
	upstream backend-lb{
		least_conn;
        server 127.0.0.1:5001;
        server 127.0.0.1:5002;
        server 127.0.0.1:5003;
    }
}
```

#### 실습: IP 해시 알고리즘
```text
http{
	# ...
	upstream backend-lb{
		ip_hash;
        server 127.0.0.1:5001;
        server 127.0.0.1:5002;
        server 127.0.0.1:5003;
    }
}
```

#### 실습: 다양한 파라미터 지정 방법
```text
http{
	# ...
	upstream backend-lb{
        server 127.0.0.1:5001 down;
        server 127.0.0.1:5002 max_fails=5 fail_timeout=15s;
        server 127.0.0.1:5003 weight=3 max_fails=5 fail_timeout=15s;
    }
}
```

#### 실습: 기본 연결 방식의 최대 연결 수(max_conns)와 대기열(queue) 지정 방법

```text
http{
	# ...
	upstream backend-lb{
        server 127.0.0.1:5001 max_conns=10;
        server 127.0.0.1:5002;
        server 127.0.0.1:5003;
        queue 20 timeout=60;
    }
}
```
- 5001 포트 서버에 최대 10개의 동시 연결만 허용
- 10개 이상의 요청이 들어오면 큐에 들어갑니다.
- 최대 20개의 요청을 큐에 대기시킵니다. 큐에서 대기중인 요청은 최대 60초까지만 허용됩니다. 60초를 넘으면 504 Gateway Timeout 에러가 발생합니다.

## 3.2.6 도커 kill 명령과 초기화
리눅스에서 프로세스 정지 방법은 systemctl와 kill 명령어를 이용한 방법이 있습니다. 도커는 docker stop을 이용하거나 docker kill 명령어를 이용하는 방법이 있습니다.

docker stop 명령어는 컨테이너 종료시 프로세스에 SIGTERM으로 종료를 전달하고, 10초전까지 종료하지 않으면 SIGKILL을 전송합니다. docker stop의 이러한 과정을 통해서 graceful shutdown을 수행합니다. 하지만 docker kill 명령어는 바로 컨테이너에 SIGKILL을 보내서 비정상적 종료 처리를 수행합니다. 그래서 특정한 상황이 안리ㅏ면 항상 정상 종료하는 것이 좋습니다.

실습에서는 kill 명령어와 docker kill 명령어의 차이를 알아봅니다.

#### 실습: kill 명령어를 이용하여 컨테이너 중지 시도
##### 1. 호스트 운영체제에서 centos 컨테이너를 실행합니다.
다음 명령어는 터미널1에서 수행한다고 가정합니다.
```shell
docker run -it --name=os_kill centos:7 bash
```
![[img/image-440.png]]
실행 결과를 보면 centos 컨테이너에 쉘 접속중인 상태입니다. kill 명령어를 다른 터미널에서 테스트하기 위해서 이 실행 상태를 유지합니다.

##### 2. 다른 터미널에서 kill 명령어를 실행
우선은 현재 실행중인 컨테이너의 PID를 확인합니다.
```shell
ps -ef | grep docker
```

![[img/image-441.png]]
실행한 결과 PID 1369112 인것을 확인합니다.

kill 명령어를 이용해서 centos를 강제로 정지시킵니다.
```shell
sudo kill -9 1369112
```
- -9 : 강제 종료

터미널 1의 실행 결과는 다음과 같습니다.
![[img/image-442.png]]
실행 결과를 보면 Killed라는 메시지를 출력하고 호스트 운영체제로 다시 돌아옵니다.

docker 명령어를 이용해서 상태를 출력합니다.
```shell
docker ps -a --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}'
```
![[img/image-443.png]]
실행 결과를 보면 Status가 Up인것을 볼수 있습니다. 이는 정지되지 않았으며 세션만 끊어진 것을 확인할 수 있습니다. 심지어 재접속도 가능합니다.
```shell
docker exec -it os_kill bash
```
![[img/image-444.png]]

위 실습을 통해서 호스트 운영체제에서 kill 명령어는 컨테이너의 연결된 세션을 중단은 시키지만 컨테이너 정지에 영향을 주지 않았다는 것을 확인할 수 있습니다.

#### 실습: docker kill 명령어를 이용하여 컨테이너 중지
##### 1. ubuntu 컨테이너 실행
```shell
docker run -it --name=ubuntu_kill ubuntu:14.04 bash
```

##### 2. docker kill 명령어로 컨테이너 중지
```shell
docker kill ubuntu_kill
```
![[img/image-445.png]]

![[img/image-446.png]]
실행 결과를 보면 ubuntu_kill 컨테이너의 상태가 Exited 인것을 확인할 수 있습니다.

#### 도커 컨테이너 정지 코드
docker kill 명령어를 이용하여 컨테이너를 종료시키면 상태값에 Exited(137)과 같이 상태와 정지 코드가 출력됩니다. 다음 표는 도커 컨테이너 정지 코드 표입니다.

| 정지 코드 | 설명                          |
| ----- | --------------------------- |
| 0     | 정상 종료                       |
| 125   | 컨테이너 실행에 사용된 명령어가 잘못된 경우    |
| 126   | 컨테이너에 사용된 명령이 실패하는 경우       |
| 127   | 컨테이너 내부에 존재하지 않는 명령을 시도한 경우 |
| 137   | 비정상 종료                      |
| 255   | 에러 코드 -1인 상태로 범위를 벗어난 종료    |

#### 실습: 사용하지 않는 이미지 삭제
```shell
docker system prune -a
```